{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250000\n",
      "85667\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, X, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "tX = np.c_[np.ones(X.shape[0]),X]\n",
    "print(len(y))\n",
    "print(len(y[y > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri0_to_drop = [\"DER_deltaeta_jet_jet\",\"DER_mass_jet_jet\",\"DER_prodeta_jet_jet\",\"DER_lep_eta_centrality\",\"PRI_jet_leading_pt\",\"PRI_jet_leading_eta\",\"PRI_jet_leading_phi\",\"PRI_jet_subleading_pt\",\"PRI_jet_subleading_eta\",\"PRI_jet_subleading_phi\"]\n",
    "pri1_to_drop = [\"DER_deltaeta_jet_jet\",\"DER_mass_jet_jet\",\"DER_prodeta_jet_jet\",\"DER_lep_eta_centrality\",\"PRI_jet_subleading_pt\",\"PRI_jet_subleading_eta\",\"PRI_jet_subleading_phi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>DER_pt_ratio_lep_tau</th>\n",
       "      <th>DER_met_phi_centrality</th>\n",
       "      <th>DER_lep_eta_centrality</th>\n",
       "      <th>PRI_tau_pt</th>\n",
       "      <th>PRI_tau_eta</th>\n",
       "      <th>PRI_tau_phi</th>\n",
       "      <th>PRI_lep_pt</th>\n",
       "      <th>PRI_lep_eta</th>\n",
       "      <th>PRI_lep_phi</th>\n",
       "      <th>PRI_met</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-49.023079</td>\n",
       "      <td>49.239819</td>\n",
       "      <td>81.181982</td>\n",
       "      <td>57.895962</td>\n",
       "      <td>-708.420675</td>\n",
       "      <td>-601.237051</td>\n",
       "      <td>-709.356603</td>\n",
       "      <td>2.373100</td>\n",
       "      <td>18.917332</td>\n",
       "      <td>158.432217</td>\n",
       "      <td>1.437609</td>\n",
       "      <td>-0.128305</td>\n",
       "      <td>-708.985189</td>\n",
       "      <td>38.707419</td>\n",
       "      <td>-0.010973</td>\n",
       "      <td>-0.008171</td>\n",
       "      <td>46.660207</td>\n",
       "      <td>-0.019507</td>\n",
       "      <td>0.043543</td>\n",
       "      <td>41.717235</td>\n",
       "      <td>-0.010119</td>\n",
       "      <td>209.797178</td>\n",
       "      <td>0.979176</td>\n",
       "      <td>-348.329567</td>\n",
       "      <td>-399.254314</td>\n",
       "      <td>-399.259788</td>\n",
       "      <td>-692.381204</td>\n",
       "      <td>-709.121609</td>\n",
       "      <td>-709.118631</td>\n",
       "      <td>73.064591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>406.345647</td>\n",
       "      <td>35.344886</td>\n",
       "      <td>40.828691</td>\n",
       "      <td>63.655682</td>\n",
       "      <td>454.480565</td>\n",
       "      <td>657.972302</td>\n",
       "      <td>453.019877</td>\n",
       "      <td>0.782911</td>\n",
       "      <td>22.273494</td>\n",
       "      <td>115.706115</td>\n",
       "      <td>0.844743</td>\n",
       "      <td>1.193585</td>\n",
       "      <td>453.596721</td>\n",
       "      <td>22.412081</td>\n",
       "      <td>1.214079</td>\n",
       "      <td>1.816763</td>\n",
       "      <td>22.064922</td>\n",
       "      <td>1.264982</td>\n",
       "      <td>1.816611</td>\n",
       "      <td>32.894693</td>\n",
       "      <td>1.812223</td>\n",
       "      <td>126.499506</td>\n",
       "      <td>0.977426</td>\n",
       "      <td>532.962789</td>\n",
       "      <td>489.338286</td>\n",
       "      <td>489.333883</td>\n",
       "      <td>479.875496</td>\n",
       "      <td>453.384624</td>\n",
       "      <td>453.389017</td>\n",
       "      <td>98.015662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.329000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.104000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>-1.414000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-2.499000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>-2.505000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>13.678000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>78.100750</td>\n",
       "      <td>19.241000</td>\n",
       "      <td>59.388750</td>\n",
       "      <td>14.068750</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>2.841000</td>\n",
       "      <td>77.550000</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>-1.371000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>24.591750</td>\n",
       "      <td>-0.925000</td>\n",
       "      <td>-1.575000</td>\n",
       "      <td>32.375000</td>\n",
       "      <td>-1.014000</td>\n",
       "      <td>-1.522000</td>\n",
       "      <td>21.398000</td>\n",
       "      <td>-1.575000</td>\n",
       "      <td>123.017500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>105.012000</td>\n",
       "      <td>46.524000</td>\n",
       "      <td>73.752000</td>\n",
       "      <td>38.467500</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>2.491500</td>\n",
       "      <td>12.315500</td>\n",
       "      <td>120.664500</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>-0.356000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>31.804000</td>\n",
       "      <td>-0.023000</td>\n",
       "      <td>-0.033000</td>\n",
       "      <td>40.516000</td>\n",
       "      <td>-0.045000</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>34.802000</td>\n",
       "      <td>-0.024000</td>\n",
       "      <td>179.739000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.960000</td>\n",
       "      <td>-1.872000</td>\n",
       "      <td>-2.093000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>40.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>130.606250</td>\n",
       "      <td>73.598000</td>\n",
       "      <td>92.259000</td>\n",
       "      <td>79.169000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>83.446000</td>\n",
       "      <td>-4.593000</td>\n",
       "      <td>2.961000</td>\n",
       "      <td>27.591000</td>\n",
       "      <td>200.478250</td>\n",
       "      <td>1.777000</td>\n",
       "      <td>1.225000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.017000</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>1.565000</td>\n",
       "      <td>53.390000</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>1.618000</td>\n",
       "      <td>51.895000</td>\n",
       "      <td>1.561000</td>\n",
       "      <td>263.379250</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>75.349000</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>33.703000</td>\n",
       "      <td>-2.457000</td>\n",
       "      <td>-2.275000</td>\n",
       "      <td>109.933750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1192.026000</td>\n",
       "      <td>690.075000</td>\n",
       "      <td>1349.351000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>8.503000</td>\n",
       "      <td>4974.979000</td>\n",
       "      <td>16.690000</td>\n",
       "      <td>5.684000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>1852.462000</td>\n",
       "      <td>19.773000</td>\n",
       "      <td>1.414000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>764.408000</td>\n",
       "      <td>2.497000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>560.271000</td>\n",
       "      <td>2.503000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>2842.617000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>2003.976000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1120.573000</td>\n",
       "      <td>4.499000</td>\n",
       "      <td>3.141000</td>\n",
       "      <td>721.456000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>1633.433000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DER_mass_MMC  DER_mass_transverse_met_lep   DER_mass_vis  \\\n",
       "count  250000.000000                250000.000000  250000.000000   \n",
       "mean      -49.023079                    49.239819      81.181982   \n",
       "std       406.345647                    35.344886      40.828691   \n",
       "min      -999.000000                     0.000000       6.329000   \n",
       "25%        78.100750                    19.241000      59.388750   \n",
       "50%       105.012000                    46.524000      73.752000   \n",
       "75%       130.606250                    73.598000      92.259000   \n",
       "max      1192.026000                   690.075000    1349.351000   \n",
       "\n",
       "            DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  \\\n",
       "count  250000.000000         250000.000000     250000.000000   \n",
       "mean       57.895962           -708.420675       -601.237051   \n",
       "std        63.655682            454.480565        657.972302   \n",
       "min         0.000000           -999.000000       -999.000000   \n",
       "25%        14.068750           -999.000000       -999.000000   \n",
       "50%        38.467500           -999.000000       -999.000000   \n",
       "75%        79.169000              0.490000         83.446000   \n",
       "max      2834.999000              8.503000       4974.979000   \n",
       "\n",
       "       DER_prodeta_jet_jet  DER_deltar_tau_lep     DER_pt_tot     DER_sum_pt  \\\n",
       "count        250000.000000       250000.000000  250000.000000  250000.000000   \n",
       "mean           -709.356603            2.373100      18.917332     158.432217   \n",
       "std             453.019877            0.782911      22.273494     115.706115   \n",
       "min            -999.000000            0.208000       0.000000      46.104000   \n",
       "25%            -999.000000            1.810000       2.841000      77.550000   \n",
       "50%            -999.000000            2.491500      12.315500     120.664500   \n",
       "75%              -4.593000            2.961000      27.591000     200.478250   \n",
       "max              16.690000            5.684000    2834.999000    1852.462000   \n",
       "\n",
       "       DER_pt_ratio_lep_tau  DER_met_phi_centrality  DER_lep_eta_centrality  \\\n",
       "count         250000.000000           250000.000000           250000.000000   \n",
       "mean               1.437609               -0.128305             -708.985189   \n",
       "std                0.844743                1.193585              453.596721   \n",
       "min                0.047000               -1.414000             -999.000000   \n",
       "25%                0.883000               -1.371000             -999.000000   \n",
       "50%                1.280000               -0.356000             -999.000000   \n",
       "75%                1.777000                1.225000                0.000000   \n",
       "max               19.773000                1.414000                1.000000   \n",
       "\n",
       "          PRI_tau_pt    PRI_tau_eta    PRI_tau_phi     PRI_lep_pt  \\\n",
       "count  250000.000000  250000.000000  250000.000000  250000.000000   \n",
       "mean       38.707419      -0.010973      -0.008171      46.660207   \n",
       "std        22.412081       1.214079       1.816763      22.064922   \n",
       "min        20.000000      -2.499000      -3.142000      26.000000   \n",
       "25%        24.591750      -0.925000      -1.575000      32.375000   \n",
       "50%        31.804000      -0.023000      -0.033000      40.516000   \n",
       "75%        45.017000       0.898000       1.565000      53.390000   \n",
       "max       764.408000       2.497000       3.142000     560.271000   \n",
       "\n",
       "         PRI_lep_eta    PRI_lep_phi        PRI_met    PRI_met_phi  \\\n",
       "count  250000.000000  250000.000000  250000.000000  250000.000000   \n",
       "mean       -0.019507       0.043543      41.717235      -0.010119   \n",
       "std         1.264982       1.816611      32.894693       1.812223   \n",
       "min        -2.505000      -3.142000       0.109000      -3.142000   \n",
       "25%        -1.014000      -1.522000      21.398000      -1.575000   \n",
       "50%        -0.045000       0.086000      34.802000      -0.024000   \n",
       "75%         0.959000       1.618000      51.895000       1.561000   \n",
       "max         2.503000       3.142000    2842.617000       3.142000   \n",
       "\n",
       "       PRI_met_sumet    PRI_jet_num  PRI_jet_leading_pt  PRI_jet_leading_eta  \\\n",
       "count  250000.000000  250000.000000       250000.000000        250000.000000   \n",
       "mean      209.797178       0.979176         -348.329567          -399.254314   \n",
       "std       126.499506       0.977426          532.962789           489.338286   \n",
       "min        13.678000       0.000000         -999.000000          -999.000000   \n",
       "25%       123.017500       0.000000         -999.000000          -999.000000   \n",
       "50%       179.739000       1.000000           38.960000            -1.872000   \n",
       "75%       263.379250       2.000000           75.349000             0.433000   \n",
       "max      2003.976000       3.000000         1120.573000             4.499000   \n",
       "\n",
       "       PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\n",
       "count        250000.000000          250000.000000           250000.000000   \n",
       "mean           -399.259788            -692.381204             -709.121609   \n",
       "std             489.333883             479.875496              453.384624   \n",
       "min            -999.000000            -999.000000             -999.000000   \n",
       "25%            -999.000000            -999.000000             -999.000000   \n",
       "50%              -2.093000            -999.000000             -999.000000   \n",
       "75%               0.503000              33.703000               -2.457000   \n",
       "max               3.141000             721.456000                4.500000   \n",
       "\n",
       "       PRI_jet_subleading_phi  PRI_jet_all_pt  \n",
       "count           250000.000000   250000.000000  \n",
       "mean              -709.118631       73.064591  \n",
       "std                453.389017       98.015662  \n",
       "min               -999.000000        0.000000  \n",
       "25%               -999.000000        0.000000  \n",
       "50%               -999.000000       40.512500  \n",
       "75%                 -2.275000      109.933750  \n",
       "max                  3.142000     1633.433000  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hb = pd.read_csv(DATA_TRAIN_PATH, sep=',')\n",
    "pd.options.display.max_columns = None\n",
    "hb = hb.drop(['Id'], 1)\n",
    "hb.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>DER_pt_ratio_lep_tau</th>\n",
       "      <th>DER_met_phi_centrality</th>\n",
       "      <th>DER_lep_eta_centrality</th>\n",
       "      <th>PRI_tau_pt</th>\n",
       "      <th>PRI_tau_eta</th>\n",
       "      <th>PRI_tau_phi</th>\n",
       "      <th>PRI_lep_pt</th>\n",
       "      <th>PRI_lep_eta</th>\n",
       "      <th>PRI_lep_phi</th>\n",
       "      <th>PRI_met</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>211886.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>150087.000000</td>\n",
       "      <td>150087.000000</td>\n",
       "      <td>150087.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>121.858528</td>\n",
       "      <td>49.239819</td>\n",
       "      <td>81.181982</td>\n",
       "      <td>57.895962</td>\n",
       "      <td>2.403735</td>\n",
       "      <td>371.783360</td>\n",
       "      <td>-0.821688</td>\n",
       "      <td>2.373100</td>\n",
       "      <td>18.917332</td>\n",
       "      <td>158.432217</td>\n",
       "      <td>1.437609</td>\n",
       "      <td>-0.128305</td>\n",
       "      <td>0.458290</td>\n",
       "      <td>38.707419</td>\n",
       "      <td>-0.010973</td>\n",
       "      <td>-0.008171</td>\n",
       "      <td>46.660207</td>\n",
       "      <td>-0.019507</td>\n",
       "      <td>0.043543</td>\n",
       "      <td>41.717235</td>\n",
       "      <td>-0.010119</td>\n",
       "      <td>209.797178</td>\n",
       "      <td>0.979176</td>\n",
       "      <td>84.822105</td>\n",
       "      <td>-0.003275</td>\n",
       "      <td>-0.012393</td>\n",
       "      <td>57.679474</td>\n",
       "      <td>-0.011845</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>73.064591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>57.298157</td>\n",
       "      <td>35.344886</td>\n",
       "      <td>40.828691</td>\n",
       "      <td>63.655682</td>\n",
       "      <td>1.742226</td>\n",
       "      <td>397.699325</td>\n",
       "      <td>3.584362</td>\n",
       "      <td>0.782911</td>\n",
       "      <td>22.273494</td>\n",
       "      <td>115.706115</td>\n",
       "      <td>0.844743</td>\n",
       "      <td>1.193585</td>\n",
       "      <td>0.398681</td>\n",
       "      <td>22.412081</td>\n",
       "      <td>1.214079</td>\n",
       "      <td>1.816763</td>\n",
       "      <td>22.064922</td>\n",
       "      <td>1.264982</td>\n",
       "      <td>1.816611</td>\n",
       "      <td>32.894693</td>\n",
       "      <td>1.812223</td>\n",
       "      <td>126.499506</td>\n",
       "      <td>0.977426</td>\n",
       "      <td>60.662276</td>\n",
       "      <td>1.784546</td>\n",
       "      <td>1.813385</td>\n",
       "      <td>31.985782</td>\n",
       "      <td>2.031743</td>\n",
       "      <td>1.816950</td>\n",
       "      <td>98.015662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>9.044000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.329000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.602000</td>\n",
       "      <td>-18.066000</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.104000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>-1.414000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-2.499000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>-2.505000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>13.678000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>-4.499000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>91.885250</td>\n",
       "      <td>19.241000</td>\n",
       "      <td>59.388750</td>\n",
       "      <td>14.068750</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>111.977000</td>\n",
       "      <td>-2.629000</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>2.841000</td>\n",
       "      <td>77.550000</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>-1.371000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>24.591750</td>\n",
       "      <td>-0.925000</td>\n",
       "      <td>-1.575000</td>\n",
       "      <td>32.375000</td>\n",
       "      <td>-1.014000</td>\n",
       "      <td>-1.522000</td>\n",
       "      <td>21.398000</td>\n",
       "      <td>-1.575000</td>\n",
       "      <td>123.017500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.422500</td>\n",
       "      <td>-1.342000</td>\n",
       "      <td>-1.584000</td>\n",
       "      <td>37.312000</td>\n",
       "      <td>-1.612000</td>\n",
       "      <td>-1.576500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>112.406000</td>\n",
       "      <td>46.524000</td>\n",
       "      <td>73.752000</td>\n",
       "      <td>38.467500</td>\n",
       "      <td>2.107000</td>\n",
       "      <td>225.885000</td>\n",
       "      <td>-0.244000</td>\n",
       "      <td>2.491500</td>\n",
       "      <td>12.315500</td>\n",
       "      <td>120.664500</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>-0.356000</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>31.804000</td>\n",
       "      <td>-0.023000</td>\n",
       "      <td>-0.033000</td>\n",
       "      <td>40.516000</td>\n",
       "      <td>-0.045000</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>34.802000</td>\n",
       "      <td>-0.024000</td>\n",
       "      <td>179.739000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.561000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.033000</td>\n",
       "      <td>47.902000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>-0.002000</td>\n",
       "      <td>40.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>135.482000</td>\n",
       "      <td>73.598000</td>\n",
       "      <td>92.259000</td>\n",
       "      <td>79.169000</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>478.226000</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>2.961000</td>\n",
       "      <td>27.591000</td>\n",
       "      <td>200.478250</td>\n",
       "      <td>1.777000</td>\n",
       "      <td>1.225000</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>45.017000</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>1.565000</td>\n",
       "      <td>53.390000</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>1.618000</td>\n",
       "      <td>51.895000</td>\n",
       "      <td>1.561000</td>\n",
       "      <td>263.379250</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>103.342000</td>\n",
       "      <td>1.336000</td>\n",
       "      <td>1.562000</td>\n",
       "      <td>66.637000</td>\n",
       "      <td>1.589500</td>\n",
       "      <td>1.576000</td>\n",
       "      <td>109.933750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1192.026000</td>\n",
       "      <td>690.075000</td>\n",
       "      <td>1349.351000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>8.503000</td>\n",
       "      <td>4974.979000</td>\n",
       "      <td>16.690000</td>\n",
       "      <td>5.684000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>1852.462000</td>\n",
       "      <td>19.773000</td>\n",
       "      <td>1.414000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>764.408000</td>\n",
       "      <td>2.497000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>560.271000</td>\n",
       "      <td>2.503000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>2842.617000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>2003.976000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1120.573000</td>\n",
       "      <td>4.499000</td>\n",
       "      <td>3.141000</td>\n",
       "      <td>721.456000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>1633.433000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DER_mass_MMC  DER_mass_transverse_met_lep   DER_mass_vis  \\\n",
       "count  211886.000000                250000.000000  250000.000000   \n",
       "mean      121.858528                    49.239819      81.181982   \n",
       "std        57.298157                    35.344886      40.828691   \n",
       "min         9.044000                     0.000000       6.329000   \n",
       "25%        91.885250                    19.241000      59.388750   \n",
       "50%       112.406000                    46.524000      73.752000   \n",
       "75%       135.482000                    73.598000      92.259000   \n",
       "max      1192.026000                   690.075000    1349.351000   \n",
       "\n",
       "            DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  \\\n",
       "count  250000.000000          72543.000000      72543.000000   \n",
       "mean       57.895962              2.403735        371.783360   \n",
       "std        63.655682              1.742226        397.699325   \n",
       "min         0.000000              0.000000         13.602000   \n",
       "25%        14.068750              0.882500        111.977000   \n",
       "50%        38.467500              2.107000        225.885000   \n",
       "75%        79.169000              3.690000        478.226000   \n",
       "max      2834.999000              8.503000       4974.979000   \n",
       "\n",
       "       DER_prodeta_jet_jet  DER_deltar_tau_lep     DER_pt_tot     DER_sum_pt  \\\n",
       "count         72543.000000       250000.000000  250000.000000  250000.000000   \n",
       "mean             -0.821688            2.373100      18.917332     158.432217   \n",
       "std               3.584362            0.782911      22.273494     115.706115   \n",
       "min             -18.066000            0.208000       0.000000      46.104000   \n",
       "25%              -2.629000            1.810000       2.841000      77.550000   \n",
       "50%              -0.244000            2.491500      12.315500     120.664500   \n",
       "75%               0.958000            2.961000      27.591000     200.478250   \n",
       "max              16.690000            5.684000    2834.999000    1852.462000   \n",
       "\n",
       "       DER_pt_ratio_lep_tau  DER_met_phi_centrality  DER_lep_eta_centrality  \\\n",
       "count         250000.000000           250000.000000            72543.000000   \n",
       "mean               1.437609               -0.128305                0.458290   \n",
       "std                0.844743                1.193585                0.398681   \n",
       "min                0.047000               -1.414000                0.000000   \n",
       "25%                0.883000               -1.371000                0.004000   \n",
       "50%                1.280000               -0.356000                0.454000   \n",
       "75%                1.777000                1.225000                0.879000   \n",
       "max               19.773000                1.414000                1.000000   \n",
       "\n",
       "          PRI_tau_pt    PRI_tau_eta    PRI_tau_phi     PRI_lep_pt  \\\n",
       "count  250000.000000  250000.000000  250000.000000  250000.000000   \n",
       "mean       38.707419      -0.010973      -0.008171      46.660207   \n",
       "std        22.412081       1.214079       1.816763      22.064922   \n",
       "min        20.000000      -2.499000      -3.142000      26.000000   \n",
       "25%        24.591750      -0.925000      -1.575000      32.375000   \n",
       "50%        31.804000      -0.023000      -0.033000      40.516000   \n",
       "75%        45.017000       0.898000       1.565000      53.390000   \n",
       "max       764.408000       2.497000       3.142000     560.271000   \n",
       "\n",
       "         PRI_lep_eta    PRI_lep_phi        PRI_met    PRI_met_phi  \\\n",
       "count  250000.000000  250000.000000  250000.000000  250000.000000   \n",
       "mean       -0.019507       0.043543      41.717235      -0.010119   \n",
       "std         1.264982       1.816611      32.894693       1.812223   \n",
       "min        -2.505000      -3.142000       0.109000      -3.142000   \n",
       "25%        -1.014000      -1.522000      21.398000      -1.575000   \n",
       "50%        -0.045000       0.086000      34.802000      -0.024000   \n",
       "75%         0.959000       1.618000      51.895000       1.561000   \n",
       "max         2.503000       3.142000    2842.617000       3.142000   \n",
       "\n",
       "       PRI_met_sumet    PRI_jet_num  PRI_jet_leading_pt  PRI_jet_leading_eta  \\\n",
       "count  250000.000000  250000.000000       150087.000000        150087.000000   \n",
       "mean      209.797178       0.979176           84.822105            -0.003275   \n",
       "std       126.499506       0.977426           60.662276             1.784546   \n",
       "min        13.678000       0.000000           30.000000            -4.499000   \n",
       "25%       123.017500       0.000000           44.422500            -1.342000   \n",
       "50%       179.739000       1.000000           65.561000             0.000000   \n",
       "75%       263.379250       2.000000          103.342000             1.336000   \n",
       "max      2003.976000       3.000000         1120.573000             4.499000   \n",
       "\n",
       "       PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\n",
       "count        150087.000000           72543.000000            72543.000000   \n",
       "mean             -0.012393              57.679474               -0.011845   \n",
       "std               1.813385              31.985782                2.031743   \n",
       "min              -3.142000              30.000000               -4.500000   \n",
       "25%              -1.584000              37.312000               -1.612000   \n",
       "50%              -0.033000              47.902000               -0.010000   \n",
       "75%               1.562000              66.637000                1.589500   \n",
       "max               3.141000             721.456000                4.500000   \n",
       "\n",
       "       PRI_jet_subleading_phi  PRI_jet_all_pt  \n",
       "count            72543.000000   250000.000000  \n",
       "mean                -0.001582       73.064591  \n",
       "std                  1.816950       98.015662  \n",
       "min                 -3.142000        0.000000  \n",
       "25%                 -1.576500        0.000000  \n",
       "50%                 -0.002000       40.512500  \n",
       "75%                  1.576000      109.933750  \n",
       "max                  3.142000     1633.433000  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hb = hb.replace(-999, np.nan)\n",
    "hb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri0 = hb[hb.PRI_jet_num==0].copy()\n",
    "pri0 = pri0.drop(pri0_to_drop,1)\n",
    "pri0 = pri0.drop([\"PRI_jet_num\",\"PRI_jet_all_pt\"],1)\n",
    "\n",
    "pri1 = hb[hb.PRI_jet_num == 1].copy()\n",
    "pri1 = pri1.drop(pri1_to_drop,1)\n",
    "pri1 = pri1.drop([\"PRI_jet_num\"],1)\n",
    "\n",
    "pri2 = hb[hb.PRI_jet_num == 2].copy()\n",
    "pri2 = pri2.drop([\"PRI_jet_num\"],1)\n",
    "\n",
    "pri3 = hb[hb.PRI_jet_num == 3].copy()\n",
    "pri3 = pri3.drop([\"PRI_jet_num\"],1)\n",
    "\n",
    "pri = [pri0,pri1,pri2,pri3]\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPredictions(dataset):\n",
    "    return dataset.Prediction.apply(lambda x: -1 if x == 'b' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataset(dataset):\n",
    "    dataset = (dataset - dataset.mean()) / dataset.std()\n",
    "    dataset = dataset.fillna(0)\n",
    "    dataset = (dataset - dataset.mean()) / dataset.std()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addX_0_constant(dataset):\n",
    "    return np.c_[np.ones(dataset.shape[0]), dataset.to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>DER_pt_ratio_lep_tau</th>\n",
       "      <th>DER_met_phi_centrality</th>\n",
       "      <th>PRI_tau_pt</th>\n",
       "      <th>PRI_tau_eta</th>\n",
       "      <th>PRI_tau_phi</th>\n",
       "      <th>PRI_lep_pt</th>\n",
       "      <th>PRI_lep_eta</th>\n",
       "      <th>PRI_lep_phi</th>\n",
       "      <th>PRI_met</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>9.991300e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>6.752636e-16</td>\n",
       "      <td>5.947310e-17</td>\n",
       "      <td>2.325331e-17</td>\n",
       "      <td>-2.342555e-17</td>\n",
       "      <td>-2.323498e-17</td>\n",
       "      <td>9.193428e-18</td>\n",
       "      <td>-4.323084e-18</td>\n",
       "      <td>1.091188e-18</td>\n",
       "      <td>1.327405e-16</td>\n",
       "      <td>-2.245381e-17</td>\n",
       "      <td>3.075773e-18</td>\n",
       "      <td>-9.607347e-18</td>\n",
       "      <td>2.421005e-17</td>\n",
       "      <td>-3.499359e-17</td>\n",
       "      <td>-1.518219e-17</td>\n",
       "      <td>-2.359167e-17</td>\n",
       "      <td>5.140808e-17</td>\n",
       "      <td>3.126444e-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-2.509911e+00</td>\n",
       "      <td>-1.836804e+00</td>\n",
       "      <td>-1.964855e+00</td>\n",
       "      <td>-8.290321e-01</td>\n",
       "      <td>-3.444365e+00</td>\n",
       "      <td>-8.290321e-01</td>\n",
       "      <td>-1.284875e+00</td>\n",
       "      <td>-2.176363e+00</td>\n",
       "      <td>-5.379732e-01</td>\n",
       "      <td>-9.201015e-01</td>\n",
       "      <td>-2.005904e+00</td>\n",
       "      <td>-1.720274e+00</td>\n",
       "      <td>-1.121919e+00</td>\n",
       "      <td>-1.871060e+00</td>\n",
       "      <td>-1.751719e+00</td>\n",
       "      <td>-1.548582e+00</td>\n",
       "      <td>-1.721450e+00</td>\n",
       "      <td>-2.113204e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-5.138304e-01</td>\n",
       "      <td>-7.413002e-01</td>\n",
       "      <td>-5.499814e-01</td>\n",
       "      <td>-6.925979e-01</td>\n",
       "      <td>-4.716048e-01</td>\n",
       "      <td>-6.925979e-01</td>\n",
       "      <td>-6.400397e-01</td>\n",
       "      <td>-7.303413e-01</td>\n",
       "      <td>-5.272975e-01</td>\n",
       "      <td>-6.801074e-01</td>\n",
       "      <td>-7.581639e-01</td>\n",
       "      <td>-8.640832e-01</td>\n",
       "      <td>-7.199577e-01</td>\n",
       "      <td>-8.152606e-01</td>\n",
       "      <td>-8.627540e-01</td>\n",
       "      <td>-6.669656e-01</td>\n",
       "      <td>-8.606024e-01</td>\n",
       "      <td>-7.141126e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-1.074078e-14</td>\n",
       "      <td>1.049184e-01</td>\n",
       "      <td>-1.665799e-01</td>\n",
       "      <td>-4.286053e-01</td>\n",
       "      <td>2.265107e-01</td>\n",
       "      <td>-4.286053e-01</td>\n",
       "      <td>-2.033445e-01</td>\n",
       "      <td>-1.285488e-01</td>\n",
       "      <td>-4.845947e-01</td>\n",
       "      <td>-3.075420e-01</td>\n",
       "      <td>-1.470887e-02</td>\n",
       "      <td>-1.834683e-02</td>\n",
       "      <td>-2.327775e-01</td>\n",
       "      <td>-3.943117e-02</td>\n",
       "      <td>2.346077e-02</td>\n",
       "      <td>-9.848760e-02</td>\n",
       "      <td>-1.466397e-02</td>\n",
       "      <td>-1.202151e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.377313e-01</td>\n",
       "      <td>6.519202e-01</td>\n",
       "      <td>3.223845e-01</td>\n",
       "      <td>6.223877e-01</td>\n",
       "      <td>6.202824e-01</td>\n",
       "      <td>6.223877e-01</td>\n",
       "      <td>3.762560e-01</td>\n",
       "      <td>5.764081e-01</td>\n",
       "      <td>-2.273104e-01</td>\n",
       "      <td>3.805287e-01</td>\n",
       "      <td>7.498256e-01</td>\n",
       "      <td>8.648066e-01</td>\n",
       "      <td>4.554177e-01</td>\n",
       "      <td>7.943756e-01</td>\n",
       "      <td>8.684178e-01</td>\n",
       "      <td>5.290211e-01</td>\n",
       "      <td>8.671661e-01</td>\n",
       "      <td>5.756102e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.670625e+01</td>\n",
       "      <td>1.597725e+01</td>\n",
       "      <td>3.331647e+01</td>\n",
       "      <td>1.691889e+02</td>\n",
       "      <td>4.354623e+00</td>\n",
       "      <td>1.691889e+02</td>\n",
       "      <td>5.298154e+01</td>\n",
       "      <td>1.578113e+01</td>\n",
       "      <td>2.481115e+00</td>\n",
       "      <td>4.795911e+01</td>\n",
       "      <td>2.042156e+00</td>\n",
       "      <td>1.737505e+00</td>\n",
       "      <td>3.550716e+01</td>\n",
       "      <td>1.949347e+00</td>\n",
       "      <td>1.705123e+00</td>\n",
       "      <td>1.385141e+02</td>\n",
       "      <td>1.748444e+00</td>\n",
       "      <td>2.384158e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis      DER_pt_h  \\\n",
       "count  9.991300e+04                 9.991300e+04  9.991300e+04  9.991300e+04   \n",
       "mean   6.752636e-16                 5.947310e-17  2.325331e-17 -2.342555e-17   \n",
       "std    1.000000e+00                 1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.509911e+00                -1.836804e+00 -1.964855e+00 -8.290321e-01   \n",
       "25%   -5.138304e-01                -7.413002e-01 -5.499814e-01 -6.925979e-01   \n",
       "50%   -1.074078e-14                 1.049184e-01 -1.665799e-01 -4.286053e-01   \n",
       "75%    1.377313e-01                 6.519202e-01  3.223845e-01  6.223877e-01   \n",
       "max    1.670625e+01                 1.597725e+01  3.331647e+01  1.691889e+02   \n",
       "\n",
       "       DER_deltar_tau_lep    DER_pt_tot    DER_sum_pt  DER_pt_ratio_lep_tau  \\\n",
       "count        9.991300e+04  9.991300e+04  9.991300e+04          9.991300e+04   \n",
       "mean        -2.323498e-17  9.193428e-18 -4.323084e-18          1.091188e-18   \n",
       "std          1.000000e+00  1.000000e+00  1.000000e+00          1.000000e+00   \n",
       "min         -3.444365e+00 -8.290321e-01 -1.284875e+00         -2.176363e+00   \n",
       "25%         -4.716048e-01 -6.925979e-01 -6.400397e-01         -7.303413e-01   \n",
       "50%          2.265107e-01 -4.286053e-01 -2.033445e-01         -1.285488e-01   \n",
       "75%          6.202824e-01  6.223877e-01  3.762560e-01          5.764081e-01   \n",
       "max          4.354623e+00  1.691889e+02  5.298154e+01          1.578113e+01   \n",
       "\n",
       "       DER_met_phi_centrality    PRI_tau_pt   PRI_tau_eta   PRI_tau_phi  \\\n",
       "count            9.991300e+04  9.991300e+04  9.991300e+04  9.991300e+04   \n",
       "mean             1.327405e-16 -2.245381e-17  3.075773e-18 -9.607347e-18   \n",
       "std              1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min             -5.379732e-01 -9.201015e-01 -2.005904e+00 -1.720274e+00   \n",
       "25%             -5.272975e-01 -6.801074e-01 -7.581639e-01 -8.640832e-01   \n",
       "50%             -4.845947e-01 -3.075420e-01 -1.470887e-02 -1.834683e-02   \n",
       "75%             -2.273104e-01  3.805287e-01  7.498256e-01  8.648066e-01   \n",
       "max              2.481115e+00  4.795911e+01  2.042156e+00  1.737505e+00   \n",
       "\n",
       "         PRI_lep_pt   PRI_lep_eta   PRI_lep_phi       PRI_met   PRI_met_phi  \\\n",
       "count  9.991300e+04  9.991300e+04  9.991300e+04  9.991300e+04  9.991300e+04   \n",
       "mean   2.421005e-17 -3.499359e-17 -1.518219e-17 -2.359167e-17  5.140808e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.121919e+00 -1.871060e+00 -1.751719e+00 -1.548582e+00 -1.721450e+00   \n",
       "25%   -7.199577e-01 -8.152606e-01 -8.627540e-01 -6.669656e-01 -8.606024e-01   \n",
       "50%   -2.327775e-01 -3.943117e-02  2.346077e-02 -9.848760e-02 -1.466397e-02   \n",
       "75%    4.554177e-01  7.943756e-01  8.684178e-01  5.290211e-01  8.671661e-01   \n",
       "max    3.550716e+01  1.949347e+00  1.705123e+00  1.385141e+02  1.748444e+00   \n",
       "\n",
       "       PRI_met_sumet  PRI_jet_num  PRI_jet_all_pt  \n",
       "count   9.991300e+04          0.0             0.0  \n",
       "mean    3.126444e-17          NaN             NaN  \n",
       "std     1.000000e+00          NaN             NaN  \n",
       "min    -2.113204e+00          NaN             NaN  \n",
       "25%    -7.141126e-01          NaN             NaN  \n",
       "50%    -1.202151e-01          NaN             NaN  \n",
       "75%     5.756102e-01          NaN             NaN  \n",
       "max     2.384158e+01          NaN             NaN  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, dataset in enumerate(pri):\n",
    "    predictions.append(extractPredictions(dataset))\n",
    "    dataset = dataset.drop(['Prediction'],1)\n",
    "    pri[idx] = normalizeDataset(dataset)\n",
    "pri[0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX = np.c_[np.ones(X.shape[0]), hb.to_numpy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3404106662758695\n"
     ]
    }
   ],
   "source": [
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"\n",
    "    Linear regression using gradient descent.\n",
    "    Uses MSE.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y:  ndarray\n",
    "        the labels\n",
    "    tx: ndarray\n",
    "        vector x tilde, i.e. the parameters with a bias term\n",
    "    initial_w: ndarray\n",
    "        initial weight vector\n",
    "    max_iters: int\n",
    "        maximum number of iterations\n",
    "    gamma: float\n",
    "        learning rate\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (ndarray, float)\n",
    "        Last weight vector and the corresponding loss value\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_e(y, tx, w):\n",
    "        return y - tx @ w\n",
    "    \n",
    "    def compute_loss(n2, e):\n",
    "        return (e.T @ e) / n2\n",
    "    \n",
    "    def compute_gradient(tx, n, e):\n",
    "        return - tx.T @ e / n\n",
    "    \n",
    "    loss = 0\n",
    "    w = initial_w\n",
    "    n = y.shape[0]\n",
    "    n2 = n*2\n",
    "    \n",
    "    for n_iter in range(max_iters):\n",
    "        e = compute_e(y, tx, w)\n",
    "        gradient = compute_gradient(tx, n, e)\n",
    "        loss = compute_loss(n2, e)\n",
    "        \n",
    "        # Update weights\n",
    "        w -= gamma * gradient\n",
    "        #print(\"Gradient Descent({bi}/{ti}): loss={l}, w={w}\".format(\n",
    "        #      bi=n_iter, ti=max_iters - 1, l=loss, w=w[0]))\n",
    "\n",
    "    return w, loss\n",
    "'''\n",
    "weights = np.array([])\n",
    "for i in range(100):\n",
    "    initial_w = np.full(tX.shape[1], i/100)\n",
    "    max_iters = 100\n",
    "    gamma = 0.3\n",
    "    w, loss = least_squares_GD(y, tX, initial_w, max_iters, gamma)\n",
    "    weights = np.append(weights, loss)\n",
    "idx = np.argmin(weights)\n",
    "'''\n",
    "initial_w = np.zeros(tX.shape[1])\n",
    "max_iters = 1000\n",
    "gamma = 0.3\n",
    "w, loss = least_squares_GD(y, tX, initial_w, max_iters, gamma)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34672967168835184\n"
     ]
    }
   ],
   "source": [
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"\n",
    "    Linear regression using gradient descent.\n",
    "    Uses MAE.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y:  ndarray\n",
    "        the labels\n",
    "    tx: ndarray\n",
    "        vector x tilde, i.e. the parameters with a bias term\n",
    "    initial_w: ndarray\n",
    "        initial weight vector\n",
    "    max_iters: int\n",
    "        maximum number of iterations\n",
    "    gamma: float\n",
    "        learning rate\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (ndarray, float)\n",
    "        Last weight vector and the corresponding loss value\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_e(y, tx, w):\n",
    "        return y - tx @ w\n",
    "    \n",
    "    def compute_loss(n, e):\n",
    "        return 1/n * np.sum(np.abs(e))\n",
    "    \n",
    "    def compute_gradient(tx, n, e):\n",
    "        e = y - tx @ w\n",
    "    \n",
    "        return -1/n*tx.T @ np.sign(e)\n",
    "    \n",
    "    loss = 0\n",
    "    w = initial_w\n",
    "    n = y.shape[0]\n",
    "    n2 = n*2\n",
    "    \n",
    "    for n_iter in range(max_iters):\n",
    "        e = compute_e(y, tx, w)\n",
    "        gradient = compute_gradient(tx, n, e)\n",
    "        loss = compute_loss(n2, e)\n",
    "        \n",
    "        # Update weights\n",
    "        w -= gamma * gradient\n",
    "        #print(\"Gradient Descent({bi}/{ti}): loss={l}, w={w}\".format(\n",
    "        #      bi=n_iter, ti=max_iters - 1, l=loss, w=w[0]))\n",
    "\n",
    "    return w, loss\n",
    "\n",
    "initial_w = np.zeros(tX.shape[1])\n",
    "max_iters = 1000\n",
    "gamma = 0.3\n",
    "w, loss = least_squares_GD(y, tX, initial_w, max_iters, gamma)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4915113296368542\n"
     ]
    }
   ],
   "source": [
    "def least_squares_SGD(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"\n",
    "    Linear regression using stochastic gradient descent.\n",
    "    Uses MAE.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y:  ndarray\n",
    "        the labels\n",
    "    tx: ndarray\n",
    "        vector x tilde, i.e. the parameters with a bias term\n",
    "    initial_w: ndarray\n",
    "        initial weight vector\n",
    "    max_iters: int\n",
    "        maximum number of iterations\n",
    "    gamma: float\n",
    "        learning rate\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (ndarray, float)\n",
    "        Last weight vector and the corresponding loss value\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_e(y, tx, w):\n",
    "        return y - tx @ w\n",
    "    \n",
    "    def compute_loss(n2, e):\n",
    "        return (e.T @ e) / n2\n",
    "    \n",
    "    def compute_gradient(tx, n, e):\n",
    "        return - tx.T @ e / n\n",
    "    \n",
    "    loss = 0\n",
    "    w = initial_w[:, np.newaxis]\n",
    "    n = y.shape[0]\n",
    "    n2 = n*2\n",
    "    data_size = len(y)\n",
    "    shuffled_indices = np.random.permutation(np.arange(data_size))\n",
    "    shuffled_y = y[shuffled_indices]\n",
    "    shuffled_tx = tx[shuffled_indices]\n",
    "    shuffled_y = shuffled_y[:,np.newaxis]\n",
    "    for n_iter, by, btx in zip(range(max_iters), shuffled_y, shuffled_tx):\n",
    "        by = by[np.newaxis]\n",
    "        btx = btx[np.newaxis, :]\n",
    "        e = compute_e(by, btx, w)\n",
    "        gradient = compute_gradient(btx, n, e)\n",
    "        loss = compute_loss(n2, e)\n",
    "        \n",
    "        # Update weights\n",
    "        w -= gamma * gradient\n",
    "        #print(\"Gradient Descent({bi}/{ti}): loss={l}, w={w}\".format(\n",
    "        #      bi=n_iter, ti=max_iters - 1, l=loss, w=w[0]))\n",
    "    return w, compute_loss(n2, compute_e(y, tx, w[:,0]))\n",
    "\n",
    "initial_w = np.full(tX.shape[1], 0.1)\n",
    "max_iters = 100000\n",
    "gamma = 0.7\n",
    "w, loss = least_squares_SGD(y, tX, initial_w, max_iters, gamma)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34040945216155494\n"
     ]
    }
   ],
   "source": [
    "def least_squares(y, tx):\n",
    "    \"\"\"\n",
    "    Linear regression using normal equations.\n",
    "    Use MSE loss function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y:  ndarray\n",
    "        the labels\n",
    "    tx: ndarray\n",
    "        vector x tilde, i.e. the parameters with a bias term\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (ndarray, float)\n",
    "        Last weight vector and the corresponding loss value\n",
    "    \"\"\"    \n",
    "    def compute_e(y, tx, w):\n",
    "        return y - tx @ w\n",
    "    \n",
    "    def compute_loss(n2, e):\n",
    "        return (e.T @ e) / n2\n",
    "    \n",
    "    w = la.solve(tx.T @ tx, tx.T @ y)\n",
    "    \n",
    "    return w, compute_loss(y.shape[0]*2, compute_e(y, tx, w))\n",
    "\n",
    "w, loss = least_squares(y, tX)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    \"\"\"\n",
    "    Ridge regression using normal equations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : ndarray\n",
    "        Description of y\n",
    "    ...\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (ndarray, float)\n",
    "        Last weight vector and the corresponding loss value\n",
    "    \"\"\" \n",
    "    \n",
    "            \n",
    "    def compute_e(y, tx, w):\n",
    "        return y - tx @ w\n",
    "    \n",
    "    def compute_loss(n2, e):\n",
    "        return (e.T @ e) / n2\n",
    "    \n",
    "    \n",
    "    X = tx.T @ tx\n",
    "    w = la.solve(X + lambda_ * (2*y.shape[0]) * np.eye(X.shape[0]), tx.T @ y)\n",
    "    return w, compute_loss(y.shape[0]*2, compute_e(y, tx, w))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.000, Training RMSE=0.583\n",
      "lambda=0.000, Training RMSE=0.583\n",
      "lambda=0.000, Training RMSE=0.583\n",
      "lambda=0.000, Training RMSE=0.583\n",
      "lambda=0.000, Training RMSE=0.583\n",
      "lambda=0.001, Training RMSE=0.583\n",
      "lambda=0.001, Training RMSE=0.583\n",
      "lambda=0.003, Training RMSE=0.583\n",
      "lambda=0.007, Training RMSE=0.584\n",
      "lambda=0.016, Training RMSE=0.584\n",
      "lambda=0.037, Training RMSE=0.586\n",
      "lambda=0.085, Training RMSE=0.590\n",
      "lambda=0.193, Training RMSE=0.598\n",
      "lambda=0.439, Training RMSE=0.613\n",
      "lambda=1.000, Training RMSE=0.634\n",
      "0.3404162668067664\n"
     ]
    }
   ],
   "source": [
    "def ridge_regression_demo(tx, y):\n",
    "\n",
    "    \n",
    "    \"\"\"ridge regression demo.\"\"\"\n",
    "    # define parameter\n",
    "    lambdas = np.logspace(-5, 0, 15)\n",
    "    \n",
    "    rmse_tr = []\n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "        weights, loss = ridge_regression(y, tx, lambda_)\n",
    "        rmse_tr.append(np.sqrt(loss))\n",
    "\n",
    "        print(\"lambda={l:.3f}, Training RMSE={tr:.3f}\".format(l=lambda_, tr=rmse_tr[ind]))\n",
    "        \n",
    "\n",
    "ridge_regression_demo(tX, y)\n",
    "\n",
    "w, loss = ridge_regression(y, tX, 0.001)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    \"\"\"apply sigmoid function on t.\"\"\"\n",
    "    return 1/(1 + np.exp(-t))\n",
    "    \n",
    "def calculate_loss(y, tx, w):\n",
    "    \"\"\"compute the cost by negative log likelihood.\"\"\"\n",
    "    return np.sum(np.log(1 + np.exp(tx @ w)) - y * (tx @ w))\n",
    "\n",
    "\n",
    "def calculate_gradient(y, tx, w):\n",
    "    \"\"\"compute the gradient of loss.\"\"\"\n",
    "    return tx.T @ (sigmoid(tx@w) - y)\n",
    "\n",
    "\n",
    "def logistic_regression_step(y, tx, w):\n",
    "    \"\"\"return the loss, gradient\"\"\"\n",
    "    return calculate_loss(y, tx, w), calculate_gradient(y, tx, w)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def logistic_regression(y, tx, lambda_):\n",
    "    \"\"\"\n",
    "    Logistic regression using gradient descent or SGD.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : ndarray\n",
    "        Description of y\n",
    "    ...\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (ndarray, float)\n",
    "        Last weight vector and the corresponding loss value\n",
    "    \"\"\"  \n",
    "    def learning_by_gradient_descent(y, tx, w, gamma):\n",
    "        \"\"\"\n",
    "        Do one step of gradient descen using logistic regression.\n",
    "        Return the loss and the updated w.\n",
    "        \"\"\"\n",
    "        loss = calculate_loss(y, tx, w)\n",
    "        gradient = calculate_gradient(y,tx,w)\n",
    "        w = w - gamma * gradient\n",
    "        return loss, w\n",
    "    \n",
    "    # init parameters\n",
    "    max_iter = 10000\n",
    "    threshold = 1e-8\n",
    "    #gamma = 0.01\n",
    "    losses = []\n",
    "\n",
    "    # build tx\n",
    "    w = np.zeros((tx.shape[1], 1))\n",
    "    y = y[:,np.newaxis]\n",
    "\n",
    "    # start the logistic regression\n",
    "    for iter in range(max_iter):\n",
    "        # get loss and update w.\n",
    "        loss, w = learning_by_gradient_descent(y, tx, w, lambda_)\n",
    "        # log info\n",
    "        if iter % 100 == 0:\n",
    "            print(\"Current iteration={i}, loss={l}\".format(i=iter, l=loss))\n",
    "        # converge criterion\n",
    "        losses.append(loss)\n",
    "        if len(losses) > 1 and np.abs(losses[-1] - losses[-2]) < threshold:\n",
    "            break\n",
    "     \n",
    "    print(\"loss={l}\".format(l=calculate_loss(y, tx, w)))\n",
    "    return w, losses[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lambda_ = 1e-8\n",
    "w, loss = logistic_regression(y, tX, lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def reg_logistic_regression(y, tx, lambda_):\n",
    "    \"\"\"\n",
    "    Regularized logistic regression using gradient descent or SGD.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : ndarray\n",
    "        Description of y\n",
    "    ...\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (ndarray, float)\n",
    "        Last weight vector and the corresponding loss value\n",
    "    \"\"\"    \n",
    "    def penalized_logistic_regression(y, tx, w, lambda_):\n",
    "        \"\"\"return the loss, gradient\"\"\"\n",
    "        loss, gradient = logistic_regression_step(y, tx, w)\n",
    "        loss     += 2 * lambda_ * la.norm(w)**2\n",
    "        gradient += lambda_ * w\n",
    "\n",
    "        return loss, gradient\n",
    "    \n",
    "    def learning_by_penalized_gradient(y, tx, w, gamma, lambda_):\n",
    "        \"\"\"\n",
    "        Do one step of gradient descent, using the penalized logistic regression.\n",
    "        Return the loss and updated w.\n",
    "        \"\"\"\n",
    "        loss, gradient = penalized_logistic_regression(y, tx, w, lambda_) \n",
    "        w = w - gamma * gradient \n",
    "\n",
    "        return loss, w\n",
    "    \n",
    "    # init parameters\n",
    "    max_iter = 10000\n",
    "    gamma = 1e-8\n",
    "    threshold = 1e-8\n",
    "    losses = []\n",
    "\n",
    "    w = np.zeros((tx.shape[1], 1))\n",
    "    y = y[:,np.newaxis]\n",
    "\n",
    "    # start the logistic regression\n",
    "    for iter in range(max_iter):\n",
    "        # get loss and update w.\n",
    "        loss, w = learning_by_penalized_gradient(y, tx, w, gamma, lambda_)\n",
    "        # log info\n",
    "        if iter % 100 == 0:\n",
    "            print(\"Current iteration={i}, loss={l}\".format(i=iter, l=loss))\n",
    "        # converge criterion\n",
    "        losses.append(loss)\n",
    "        if len(losses) > 1 and np.abs(losses[-1] - losses[-2]) < threshold:\n",
    "            break\n",
    "            \n",
    "    print(\"loss={l}\".format(l=calculate_loss(y, tx, w)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lambda_ = 0.000001\n",
    "w, loss = reg_logistic_regression(y, tX, lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "hbt = pd.read_csv(DATA_TEST_PATH, sep=',')\n",
    "hbt = hbt.drop(['Id', 'Prediction'], 1)\n",
    "hbt = hbt.replace(-999, np.nan)\n",
    "hbt = (hbt - hbt.mean()) / hbt.std()\n",
    "hbt = hbt.fillna(0)\n",
    "hbt = (hbt - hbt.mean()) / hbt.std()\n",
    "tX_test = hbt.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'predictions.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w[1:], tX_test)#[:, [0, 1, 2, 3, 4, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]]) # Selected desired columns\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_pred))\n",
    "print(len(y_pred[y_pred > 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submissions scores\n",
    "Best score by technique\n",
    "\n",
    "<ul>\n",
    "    <li>MSE, gradient descent : 0.649</li>\n",
    "    <li>MAE, gradient descent : 0.678 </li>\n",
    "    <li>ridge regression      : 0.664</li>\n",
    "</ul>\n",
    "Best score after not being stupid with bias:\n",
    "\n",
    "* MSE, GD: \n",
    "* MAE, GD: 0.639\n",
    "* LSQ: 0.706\n",
    "* R-REG: 0.730\n",
    "\n",
    "Best score after normalizing test set + putting zero where unknown:\n",
    "\n",
    "* LSQ: 0.723\n",
    "* R-REG: 0.719\n",
    "\n",
    "Feature expansion?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
