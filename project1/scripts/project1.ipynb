{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250000\n",
      "85667\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, X, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "tX = np.c_[np.ones(X.shape[0]),X]\n",
    "print(len(y))\n",
    "print(len(y[y > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>DER_pt_ratio_lep_tau</th>\n",
       "      <th>DER_met_phi_centrality</th>\n",
       "      <th>DER_lep_eta_centrality</th>\n",
       "      <th>PRI_tau_pt</th>\n",
       "      <th>PRI_tau_eta</th>\n",
       "      <th>PRI_tau_phi</th>\n",
       "      <th>PRI_lep_pt</th>\n",
       "      <th>PRI_lep_eta</th>\n",
       "      <th>PRI_lep_phi</th>\n",
       "      <th>PRI_met</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-49.023079</td>\n",
       "      <td>49.239819</td>\n",
       "      <td>81.181982</td>\n",
       "      <td>57.895962</td>\n",
       "      <td>-708.420675</td>\n",
       "      <td>-601.237051</td>\n",
       "      <td>-709.356603</td>\n",
       "      <td>2.373100</td>\n",
       "      <td>18.917332</td>\n",
       "      <td>158.432217</td>\n",
       "      <td>1.437609</td>\n",
       "      <td>-0.128305</td>\n",
       "      <td>-708.985189</td>\n",
       "      <td>38.707419</td>\n",
       "      <td>-0.010973</td>\n",
       "      <td>-0.008171</td>\n",
       "      <td>46.660207</td>\n",
       "      <td>-0.019507</td>\n",
       "      <td>0.043543</td>\n",
       "      <td>41.717235</td>\n",
       "      <td>-0.010119</td>\n",
       "      <td>209.797178</td>\n",
       "      <td>0.979176</td>\n",
       "      <td>-348.329567</td>\n",
       "      <td>-399.254314</td>\n",
       "      <td>-399.259788</td>\n",
       "      <td>-692.381204</td>\n",
       "      <td>-709.121609</td>\n",
       "      <td>-709.118631</td>\n",
       "      <td>73.064591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>406.345647</td>\n",
       "      <td>35.344886</td>\n",
       "      <td>40.828691</td>\n",
       "      <td>63.655682</td>\n",
       "      <td>454.480565</td>\n",
       "      <td>657.972302</td>\n",
       "      <td>453.019877</td>\n",
       "      <td>0.782911</td>\n",
       "      <td>22.273494</td>\n",
       "      <td>115.706115</td>\n",
       "      <td>0.844743</td>\n",
       "      <td>1.193585</td>\n",
       "      <td>453.596721</td>\n",
       "      <td>22.412081</td>\n",
       "      <td>1.214079</td>\n",
       "      <td>1.816763</td>\n",
       "      <td>22.064922</td>\n",
       "      <td>1.264982</td>\n",
       "      <td>1.816611</td>\n",
       "      <td>32.894693</td>\n",
       "      <td>1.812223</td>\n",
       "      <td>126.499506</td>\n",
       "      <td>0.977426</td>\n",
       "      <td>532.962789</td>\n",
       "      <td>489.338286</td>\n",
       "      <td>489.333883</td>\n",
       "      <td>479.875496</td>\n",
       "      <td>453.384624</td>\n",
       "      <td>453.389017</td>\n",
       "      <td>98.015662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.329000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.104000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>-1.414000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-2.499000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>-2.505000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>13.678000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>78.100750</td>\n",
       "      <td>19.241000</td>\n",
       "      <td>59.388750</td>\n",
       "      <td>14.068750</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>2.841000</td>\n",
       "      <td>77.550000</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>-1.371000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>24.591750</td>\n",
       "      <td>-0.925000</td>\n",
       "      <td>-1.575000</td>\n",
       "      <td>32.375000</td>\n",
       "      <td>-1.014000</td>\n",
       "      <td>-1.522000</td>\n",
       "      <td>21.398000</td>\n",
       "      <td>-1.575000</td>\n",
       "      <td>123.017500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>105.012000</td>\n",
       "      <td>46.524000</td>\n",
       "      <td>73.752000</td>\n",
       "      <td>38.467500</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>2.491500</td>\n",
       "      <td>12.315500</td>\n",
       "      <td>120.664500</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>-0.356000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>31.804000</td>\n",
       "      <td>-0.023000</td>\n",
       "      <td>-0.033000</td>\n",
       "      <td>40.516000</td>\n",
       "      <td>-0.045000</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>34.802000</td>\n",
       "      <td>-0.024000</td>\n",
       "      <td>179.739000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.960000</td>\n",
       "      <td>-1.872000</td>\n",
       "      <td>-2.093000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>40.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>130.606250</td>\n",
       "      <td>73.598000</td>\n",
       "      <td>92.259000</td>\n",
       "      <td>79.169000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>83.446000</td>\n",
       "      <td>-4.593000</td>\n",
       "      <td>2.961000</td>\n",
       "      <td>27.591000</td>\n",
       "      <td>200.478250</td>\n",
       "      <td>1.777000</td>\n",
       "      <td>1.225000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.017000</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>1.565000</td>\n",
       "      <td>53.390000</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>1.618000</td>\n",
       "      <td>51.895000</td>\n",
       "      <td>1.561000</td>\n",
       "      <td>263.379250</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>75.349000</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>33.703000</td>\n",
       "      <td>-2.457000</td>\n",
       "      <td>-2.275000</td>\n",
       "      <td>109.933750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1192.026000</td>\n",
       "      <td>690.075000</td>\n",
       "      <td>1349.351000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>8.503000</td>\n",
       "      <td>4974.979000</td>\n",
       "      <td>16.690000</td>\n",
       "      <td>5.684000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>1852.462000</td>\n",
       "      <td>19.773000</td>\n",
       "      <td>1.414000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>764.408000</td>\n",
       "      <td>2.497000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>560.271000</td>\n",
       "      <td>2.503000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>2842.617000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>2003.976000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1120.573000</td>\n",
       "      <td>4.499000</td>\n",
       "      <td>3.141000</td>\n",
       "      <td>721.456000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>1633.433000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DER_mass_MMC  DER_mass_transverse_met_lep   DER_mass_vis  \\\n",
       "count  250000.000000                250000.000000  250000.000000   \n",
       "mean      -49.023079                    49.239819      81.181982   \n",
       "std       406.345647                    35.344886      40.828691   \n",
       "min      -999.000000                     0.000000       6.329000   \n",
       "25%        78.100750                    19.241000      59.388750   \n",
       "50%       105.012000                    46.524000      73.752000   \n",
       "75%       130.606250                    73.598000      92.259000   \n",
       "max      1192.026000                   690.075000    1349.351000   \n",
       "\n",
       "            DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  \\\n",
       "count  250000.000000         250000.000000     250000.000000   \n",
       "mean       57.895962           -708.420675       -601.237051   \n",
       "std        63.655682            454.480565        657.972302   \n",
       "min         0.000000           -999.000000       -999.000000   \n",
       "25%        14.068750           -999.000000       -999.000000   \n",
       "50%        38.467500           -999.000000       -999.000000   \n",
       "75%        79.169000              0.490000         83.446000   \n",
       "max      2834.999000              8.503000       4974.979000   \n",
       "\n",
       "       DER_prodeta_jet_jet  DER_deltar_tau_lep     DER_pt_tot     DER_sum_pt  \\\n",
       "count        250000.000000       250000.000000  250000.000000  250000.000000   \n",
       "mean           -709.356603            2.373100      18.917332     158.432217   \n",
       "std             453.019877            0.782911      22.273494     115.706115   \n",
       "min            -999.000000            0.208000       0.000000      46.104000   \n",
       "25%            -999.000000            1.810000       2.841000      77.550000   \n",
       "50%            -999.000000            2.491500      12.315500     120.664500   \n",
       "75%              -4.593000            2.961000      27.591000     200.478250   \n",
       "max              16.690000            5.684000    2834.999000    1852.462000   \n",
       "\n",
       "       DER_pt_ratio_lep_tau  DER_met_phi_centrality  DER_lep_eta_centrality  \\\n",
       "count         250000.000000           250000.000000           250000.000000   \n",
       "mean               1.437609               -0.128305             -708.985189   \n",
       "std                0.844743                1.193585              453.596721   \n",
       "min                0.047000               -1.414000             -999.000000   \n",
       "25%                0.883000               -1.371000             -999.000000   \n",
       "50%                1.280000               -0.356000             -999.000000   \n",
       "75%                1.777000                1.225000                0.000000   \n",
       "max               19.773000                1.414000                1.000000   \n",
       "\n",
       "          PRI_tau_pt    PRI_tau_eta    PRI_tau_phi     PRI_lep_pt  \\\n",
       "count  250000.000000  250000.000000  250000.000000  250000.000000   \n",
       "mean       38.707419      -0.010973      -0.008171      46.660207   \n",
       "std        22.412081       1.214079       1.816763      22.064922   \n",
       "min        20.000000      -2.499000      -3.142000      26.000000   \n",
       "25%        24.591750      -0.925000      -1.575000      32.375000   \n",
       "50%        31.804000      -0.023000      -0.033000      40.516000   \n",
       "75%        45.017000       0.898000       1.565000      53.390000   \n",
       "max       764.408000       2.497000       3.142000     560.271000   \n",
       "\n",
       "         PRI_lep_eta    PRI_lep_phi        PRI_met    PRI_met_phi  \\\n",
       "count  250000.000000  250000.000000  250000.000000  250000.000000   \n",
       "mean       -0.019507       0.043543      41.717235      -0.010119   \n",
       "std         1.264982       1.816611      32.894693       1.812223   \n",
       "min        -2.505000      -3.142000       0.109000      -3.142000   \n",
       "25%        -1.014000      -1.522000      21.398000      -1.575000   \n",
       "50%        -0.045000       0.086000      34.802000      -0.024000   \n",
       "75%         0.959000       1.618000      51.895000       1.561000   \n",
       "max         2.503000       3.142000    2842.617000       3.142000   \n",
       "\n",
       "       PRI_met_sumet    PRI_jet_num  PRI_jet_leading_pt  PRI_jet_leading_eta  \\\n",
       "count  250000.000000  250000.000000       250000.000000        250000.000000   \n",
       "mean      209.797178       0.979176         -348.329567          -399.254314   \n",
       "std       126.499506       0.977426          532.962789           489.338286   \n",
       "min        13.678000       0.000000         -999.000000          -999.000000   \n",
       "25%       123.017500       0.000000         -999.000000          -999.000000   \n",
       "50%       179.739000       1.000000           38.960000            -1.872000   \n",
       "75%       263.379250       2.000000           75.349000             0.433000   \n",
       "max      2003.976000       3.000000         1120.573000             4.499000   \n",
       "\n",
       "       PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\n",
       "count        250000.000000          250000.000000           250000.000000   \n",
       "mean           -399.259788            -692.381204             -709.121609   \n",
       "std             489.333883             479.875496              453.384624   \n",
       "min            -999.000000            -999.000000             -999.000000   \n",
       "25%            -999.000000            -999.000000             -999.000000   \n",
       "50%              -2.093000            -999.000000             -999.000000   \n",
       "75%               0.503000              33.703000               -2.457000   \n",
       "max               3.141000             721.456000                4.500000   \n",
       "\n",
       "       PRI_jet_subleading_phi  PRI_jet_all_pt  \n",
       "count           250000.000000   250000.000000  \n",
       "mean              -709.118631       73.064591  \n",
       "std                453.389017       98.015662  \n",
       "min               -999.000000        0.000000  \n",
       "25%               -999.000000        0.000000  \n",
       "50%               -999.000000       40.512500  \n",
       "75%                 -2.275000      109.933750  \n",
       "max                  3.142000     1633.433000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hb = pd.read_csv(DATA_TRAIN_PATH, sep=',')\n",
    "pd.options.display.max_columns = None\n",
    "hb = hb.drop(['Id', 'Prediction'], 1)\n",
    "hb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>DER_pt_ratio_lep_tau</th>\n",
       "      <th>DER_met_phi_centrality</th>\n",
       "      <th>DER_lep_eta_centrality</th>\n",
       "      <th>PRI_tau_pt</th>\n",
       "      <th>PRI_tau_eta</th>\n",
       "      <th>PRI_tau_phi</th>\n",
       "      <th>PRI_lep_pt</th>\n",
       "      <th>PRI_lep_eta</th>\n",
       "      <th>PRI_lep_phi</th>\n",
       "      <th>PRI_met</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>211886.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>150087.000000</td>\n",
       "      <td>150087.000000</td>\n",
       "      <td>150087.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>121.858528</td>\n",
       "      <td>49.239819</td>\n",
       "      <td>81.181982</td>\n",
       "      <td>57.895962</td>\n",
       "      <td>2.403735</td>\n",
       "      <td>371.783360</td>\n",
       "      <td>-0.821688</td>\n",
       "      <td>2.373100</td>\n",
       "      <td>18.917332</td>\n",
       "      <td>158.432217</td>\n",
       "      <td>1.437609</td>\n",
       "      <td>-0.128305</td>\n",
       "      <td>0.458290</td>\n",
       "      <td>38.707419</td>\n",
       "      <td>-0.010973</td>\n",
       "      <td>-0.008171</td>\n",
       "      <td>46.660207</td>\n",
       "      <td>-0.019507</td>\n",
       "      <td>0.043543</td>\n",
       "      <td>41.717235</td>\n",
       "      <td>-0.010119</td>\n",
       "      <td>209.797178</td>\n",
       "      <td>0.979176</td>\n",
       "      <td>84.822105</td>\n",
       "      <td>-0.003275</td>\n",
       "      <td>-0.012393</td>\n",
       "      <td>57.679474</td>\n",
       "      <td>-0.011845</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>73.064591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>57.298157</td>\n",
       "      <td>35.344886</td>\n",
       "      <td>40.828691</td>\n",
       "      <td>63.655682</td>\n",
       "      <td>1.742226</td>\n",
       "      <td>397.699325</td>\n",
       "      <td>3.584362</td>\n",
       "      <td>0.782911</td>\n",
       "      <td>22.273494</td>\n",
       "      <td>115.706115</td>\n",
       "      <td>0.844743</td>\n",
       "      <td>1.193585</td>\n",
       "      <td>0.398681</td>\n",
       "      <td>22.412081</td>\n",
       "      <td>1.214079</td>\n",
       "      <td>1.816763</td>\n",
       "      <td>22.064922</td>\n",
       "      <td>1.264982</td>\n",
       "      <td>1.816611</td>\n",
       "      <td>32.894693</td>\n",
       "      <td>1.812223</td>\n",
       "      <td>126.499506</td>\n",
       "      <td>0.977426</td>\n",
       "      <td>60.662276</td>\n",
       "      <td>1.784546</td>\n",
       "      <td>1.813385</td>\n",
       "      <td>31.985782</td>\n",
       "      <td>2.031743</td>\n",
       "      <td>1.816950</td>\n",
       "      <td>98.015662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>9.044000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.329000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.602000</td>\n",
       "      <td>-18.066000</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.104000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>-1.414000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-2.499000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>-2.505000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>13.678000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>-4.499000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>91.885250</td>\n",
       "      <td>19.241000</td>\n",
       "      <td>59.388750</td>\n",
       "      <td>14.068750</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>111.977000</td>\n",
       "      <td>-2.629000</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>2.841000</td>\n",
       "      <td>77.550000</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>-1.371000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>24.591750</td>\n",
       "      <td>-0.925000</td>\n",
       "      <td>-1.575000</td>\n",
       "      <td>32.375000</td>\n",
       "      <td>-1.014000</td>\n",
       "      <td>-1.522000</td>\n",
       "      <td>21.398000</td>\n",
       "      <td>-1.575000</td>\n",
       "      <td>123.017500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.422500</td>\n",
       "      <td>-1.342000</td>\n",
       "      <td>-1.584000</td>\n",
       "      <td>37.312000</td>\n",
       "      <td>-1.612000</td>\n",
       "      <td>-1.576500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>112.406000</td>\n",
       "      <td>46.524000</td>\n",
       "      <td>73.752000</td>\n",
       "      <td>38.467500</td>\n",
       "      <td>2.107000</td>\n",
       "      <td>225.885000</td>\n",
       "      <td>-0.244000</td>\n",
       "      <td>2.491500</td>\n",
       "      <td>12.315500</td>\n",
       "      <td>120.664500</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>-0.356000</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>31.804000</td>\n",
       "      <td>-0.023000</td>\n",
       "      <td>-0.033000</td>\n",
       "      <td>40.516000</td>\n",
       "      <td>-0.045000</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>34.802000</td>\n",
       "      <td>-0.024000</td>\n",
       "      <td>179.739000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.561000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.033000</td>\n",
       "      <td>47.902000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>-0.002000</td>\n",
       "      <td>40.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>135.482000</td>\n",
       "      <td>73.598000</td>\n",
       "      <td>92.259000</td>\n",
       "      <td>79.169000</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>478.226000</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>2.961000</td>\n",
       "      <td>27.591000</td>\n",
       "      <td>200.478250</td>\n",
       "      <td>1.777000</td>\n",
       "      <td>1.225000</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>45.017000</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>1.565000</td>\n",
       "      <td>53.390000</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>1.618000</td>\n",
       "      <td>51.895000</td>\n",
       "      <td>1.561000</td>\n",
       "      <td>263.379250</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>103.342000</td>\n",
       "      <td>1.336000</td>\n",
       "      <td>1.562000</td>\n",
       "      <td>66.637000</td>\n",
       "      <td>1.589500</td>\n",
       "      <td>1.576000</td>\n",
       "      <td>109.933750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1192.026000</td>\n",
       "      <td>690.075000</td>\n",
       "      <td>1349.351000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>8.503000</td>\n",
       "      <td>4974.979000</td>\n",
       "      <td>16.690000</td>\n",
       "      <td>5.684000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>1852.462000</td>\n",
       "      <td>19.773000</td>\n",
       "      <td>1.414000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>764.408000</td>\n",
       "      <td>2.497000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>560.271000</td>\n",
       "      <td>2.503000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>2842.617000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>2003.976000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1120.573000</td>\n",
       "      <td>4.499000</td>\n",
       "      <td>3.141000</td>\n",
       "      <td>721.456000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>1633.433000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DER_mass_MMC  DER_mass_transverse_met_lep   DER_mass_vis  \\\n",
       "count  211886.000000                250000.000000  250000.000000   \n",
       "mean      121.858528                    49.239819      81.181982   \n",
       "std        57.298157                    35.344886      40.828691   \n",
       "min         9.044000                     0.000000       6.329000   \n",
       "25%        91.885250                    19.241000      59.388750   \n",
       "50%       112.406000                    46.524000      73.752000   \n",
       "75%       135.482000                    73.598000      92.259000   \n",
       "max      1192.026000                   690.075000    1349.351000   \n",
       "\n",
       "            DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  \\\n",
       "count  250000.000000          72543.000000      72543.000000   \n",
       "mean       57.895962              2.403735        371.783360   \n",
       "std        63.655682              1.742226        397.699325   \n",
       "min         0.000000              0.000000         13.602000   \n",
       "25%        14.068750              0.882500        111.977000   \n",
       "50%        38.467500              2.107000        225.885000   \n",
       "75%        79.169000              3.690000        478.226000   \n",
       "max      2834.999000              8.503000       4974.979000   \n",
       "\n",
       "       DER_prodeta_jet_jet  DER_deltar_tau_lep     DER_pt_tot     DER_sum_pt  \\\n",
       "count         72543.000000       250000.000000  250000.000000  250000.000000   \n",
       "mean             -0.821688            2.373100      18.917332     158.432217   \n",
       "std               3.584362            0.782911      22.273494     115.706115   \n",
       "min             -18.066000            0.208000       0.000000      46.104000   \n",
       "25%              -2.629000            1.810000       2.841000      77.550000   \n",
       "50%              -0.244000            2.491500      12.315500     120.664500   \n",
       "75%               0.958000            2.961000      27.591000     200.478250   \n",
       "max              16.690000            5.684000    2834.999000    1852.462000   \n",
       "\n",
       "       DER_pt_ratio_lep_tau  DER_met_phi_centrality  DER_lep_eta_centrality  \\\n",
       "count         250000.000000           250000.000000            72543.000000   \n",
       "mean               1.437609               -0.128305                0.458290   \n",
       "std                0.844743                1.193585                0.398681   \n",
       "min                0.047000               -1.414000                0.000000   \n",
       "25%                0.883000               -1.371000                0.004000   \n",
       "50%                1.280000               -0.356000                0.454000   \n",
       "75%                1.777000                1.225000                0.879000   \n",
       "max               19.773000                1.414000                1.000000   \n",
       "\n",
       "          PRI_tau_pt    PRI_tau_eta    PRI_tau_phi     PRI_lep_pt  \\\n",
       "count  250000.000000  250000.000000  250000.000000  250000.000000   \n",
       "mean       38.707419      -0.010973      -0.008171      46.660207   \n",
       "std        22.412081       1.214079       1.816763      22.064922   \n",
       "min        20.000000      -2.499000      -3.142000      26.000000   \n",
       "25%        24.591750      -0.925000      -1.575000      32.375000   \n",
       "50%        31.804000      -0.023000      -0.033000      40.516000   \n",
       "75%        45.017000       0.898000       1.565000      53.390000   \n",
       "max       764.408000       2.497000       3.142000     560.271000   \n",
       "\n",
       "         PRI_lep_eta    PRI_lep_phi        PRI_met    PRI_met_phi  \\\n",
       "count  250000.000000  250000.000000  250000.000000  250000.000000   \n",
       "mean       -0.019507       0.043543      41.717235      -0.010119   \n",
       "std         1.264982       1.816611      32.894693       1.812223   \n",
       "min        -2.505000      -3.142000       0.109000      -3.142000   \n",
       "25%        -1.014000      -1.522000      21.398000      -1.575000   \n",
       "50%        -0.045000       0.086000      34.802000      -0.024000   \n",
       "75%         0.959000       1.618000      51.895000       1.561000   \n",
       "max         2.503000       3.142000    2842.617000       3.142000   \n",
       "\n",
       "       PRI_met_sumet    PRI_jet_num  PRI_jet_leading_pt  PRI_jet_leading_eta  \\\n",
       "count  250000.000000  250000.000000       150087.000000        150087.000000   \n",
       "mean      209.797178       0.979176           84.822105            -0.003275   \n",
       "std       126.499506       0.977426           60.662276             1.784546   \n",
       "min        13.678000       0.000000           30.000000            -4.499000   \n",
       "25%       123.017500       0.000000           44.422500            -1.342000   \n",
       "50%       179.739000       1.000000           65.561000             0.000000   \n",
       "75%       263.379250       2.000000          103.342000             1.336000   \n",
       "max      2003.976000       3.000000         1120.573000             4.499000   \n",
       "\n",
       "       PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\n",
       "count        150087.000000           72543.000000            72543.000000   \n",
       "mean             -0.012393              57.679474               -0.011845   \n",
       "std               1.813385              31.985782                2.031743   \n",
       "min              -3.142000              30.000000               -4.500000   \n",
       "25%              -1.584000              37.312000               -1.612000   \n",
       "50%              -0.033000              47.902000               -0.010000   \n",
       "75%               1.562000              66.637000                1.589500   \n",
       "max               3.141000             721.456000                4.500000   \n",
       "\n",
       "       PRI_jet_subleading_phi  PRI_jet_all_pt  \n",
       "count            72543.000000   250000.000000  \n",
       "mean                -0.001582       73.064591  \n",
       "std                  1.816950       98.015662  \n",
       "min                 -3.142000        0.000000  \n",
       "25%                 -1.576500        0.000000  \n",
       "50%                 -0.002000       40.512500  \n",
       "75%                  1.576000      109.933750  \n",
       "max                  3.142000     1633.433000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hb = hb.replace(-999, np.nan)\n",
    "hb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>DER_pt_ratio_lep_tau</th>\n",
       "      <th>DER_met_phi_centrality</th>\n",
       "      <th>DER_lep_eta_centrality</th>\n",
       "      <th>PRI_tau_pt</th>\n",
       "      <th>PRI_tau_eta</th>\n",
       "      <th>PRI_tau_phi</th>\n",
       "      <th>PRI_lep_pt</th>\n",
       "      <th>PRI_lep_eta</th>\n",
       "      <th>PRI_lep_phi</th>\n",
       "      <th>PRI_met</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-1.060130e-17</td>\n",
       "      <td>1.880096e-17</td>\n",
       "      <td>1.267608e-17</td>\n",
       "      <td>-1.631406e-17</td>\n",
       "      <td>-8.583356e-18</td>\n",
       "      <td>-1.472245e-17</td>\n",
       "      <td>8.242296e-18</td>\n",
       "      <td>2.302158e-17</td>\n",
       "      <td>-8.014922e-18</td>\n",
       "      <td>-2.677325e-17</td>\n",
       "      <td>-6.988898e-17</td>\n",
       "      <td>-7.356959e-16</td>\n",
       "      <td>-5.556444e-17</td>\n",
       "      <td>4.973799e-17</td>\n",
       "      <td>-4.428102e-17</td>\n",
       "      <td>9.094947e-18</td>\n",
       "      <td>-2.725642e-17</td>\n",
       "      <td>6.201617e-17</td>\n",
       "      <td>2.148681e-17</td>\n",
       "      <td>1.023182e-17</td>\n",
       "      <td>-3.541345e-17</td>\n",
       "      <td>-3.922196e-17</td>\n",
       "      <td>1.925912e-15</td>\n",
       "      <td>7.162271e-18</td>\n",
       "      <td>-2.131628e-18</td>\n",
       "      <td>1.347189e-17</td>\n",
       "      <td>-4.868639e-17</td>\n",
       "      <td>1.516298e-17</td>\n",
       "      <td>-2.434319e-17</td>\n",
       "      <td>-5.082654e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-2.138668e+00</td>\n",
       "      <td>-1.393124e+00</td>\n",
       "      <td>-1.833343e+00</td>\n",
       "      <td>-9.095176e-01</td>\n",
       "      <td>-2.561276e+00</td>\n",
       "      <td>-1.671947e+00</td>\n",
       "      <td>-8.931170e+00</td>\n",
       "      <td>-2.765448e+00</td>\n",
       "      <td>-8.493204e-01</td>\n",
       "      <td>-9.708062e-01</td>\n",
       "      <td>-1.646192e+00</td>\n",
       "      <td>-1.077171e+00</td>\n",
       "      <td>-2.133972e+00</td>\n",
       "      <td>-8.347025e-01</td>\n",
       "      <td>-2.049313e+00</td>\n",
       "      <td>-1.724952e+00</td>\n",
       "      <td>-9.363372e-01</td>\n",
       "      <td>-1.964844e+00</td>\n",
       "      <td>-1.753563e+00</td>\n",
       "      <td>-1.264892e+00</td>\n",
       "      <td>-1.728199e+00</td>\n",
       "      <td>-1.550355e+00</td>\n",
       "      <td>-1.001790e+00</td>\n",
       "      <td>-1.166369e+00</td>\n",
       "      <td>-3.251405e+00</td>\n",
       "      <td>-2.227403e+00</td>\n",
       "      <td>-1.606480e+00</td>\n",
       "      <td>-4.100846e+00</td>\n",
       "      <td>-3.208624e+00</td>\n",
       "      <td>-7.454379e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-4.965607e-01</td>\n",
       "      <td>-8.487457e-01</td>\n",
       "      <td>-5.337725e-01</td>\n",
       "      <td>-6.885043e-01</td>\n",
       "      <td>8.928376e-15</td>\n",
       "      <td>-5.058597e-15</td>\n",
       "      <td>-1.206744e-15</td>\n",
       "      <td>-7.192385e-01</td>\n",
       "      <td>-7.217697e-01</td>\n",
       "      <td>-6.990315e-01</td>\n",
       "      <td>-6.565422e-01</td>\n",
       "      <td>-1.041145e+00</td>\n",
       "      <td>4.104437e-15</td>\n",
       "      <td>-6.298241e-01</td>\n",
       "      <td>-7.528565e-01</td>\n",
       "      <td>-8.624289e-01</td>\n",
       "      <td>-6.474171e-01</td>\n",
       "      <td>-7.861712e-01</td>\n",
       "      <td>-8.617931e-01</td>\n",
       "      <td>-6.177055e-01</td>\n",
       "      <td>-8.635146e-01</td>\n",
       "      <td>-6.860080e-01</td>\n",
       "      <td>-1.001790e+00</td>\n",
       "      <td>-5.825900e-01</td>\n",
       "      <td>-3.107866e-01</td>\n",
       "      <td>-3.868959e-01</td>\n",
       "      <td>1.991853e-15</td>\n",
       "      <td>-2.136316e-17</td>\n",
       "      <td>2.495579e-17</td>\n",
       "      <td>-7.454379e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-3.602904e-02</td>\n",
       "      <td>-7.683769e-02</td>\n",
       "      <td>-1.819794e-01</td>\n",
       "      <td>-3.052117e-01</td>\n",
       "      <td>8.928376e-15</td>\n",
       "      <td>-5.058597e-15</td>\n",
       "      <td>-1.206744e-15</td>\n",
       "      <td>1.512306e-01</td>\n",
       "      <td>-2.963986e-01</td>\n",
       "      <td>-3.264107e-01</td>\n",
       "      <td>-1.865768e-01</td>\n",
       "      <td>-1.907659e-01</td>\n",
       "      <td>4.104437e-15</td>\n",
       "      <td>-3.080222e-01</td>\n",
       "      <td>-9.906238e-03</td>\n",
       "      <td>-1.366657e-02</td>\n",
       "      <td>-2.784604e-01</td>\n",
       "      <td>-2.015248e-02</td>\n",
       "      <td>2.337156e-02</td>\n",
       "      <td>-2.102234e-01</td>\n",
       "      <td>-7.659549e-03</td>\n",
       "      <td>-2.376150e-01</td>\n",
       "      <td>2.130493e-02</td>\n",
       "      <td>4.465373e-15</td>\n",
       "      <td>-3.438908e-19</td>\n",
       "      <td>-7.296359e-17</td>\n",
       "      <td>1.991853e-15</td>\n",
       "      <td>-2.136316e-17</td>\n",
       "      <td>2.495579e-17</td>\n",
       "      <td>-3.321111e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.658339e-01</td>\n",
       "      <td>6.891572e-01</td>\n",
       "      <td>2.713048e-01</td>\n",
       "      <td>3.341892e-01</td>\n",
       "      <td>8.928376e-15</td>\n",
       "      <td>-5.058597e-15</td>\n",
       "      <td>-1.206744e-15</td>\n",
       "      <td>7.509156e-01</td>\n",
       "      <td>3.894166e-01</td>\n",
       "      <td>3.633864e-01</td>\n",
       "      <td>4.017679e-01</td>\n",
       "      <td>1.133815e+00</td>\n",
       "      <td>4.104437e-15</td>\n",
       "      <td>2.815259e-01</td>\n",
       "      <td>7.486937e-01</td>\n",
       "      <td>8.659198e-01</td>\n",
       "      <td>3.049996e-01</td>\n",
       "      <td>7.735346e-01</td>\n",
       "      <td>8.667000e-01</td>\n",
       "      <td>3.094045e-01</td>\n",
       "      <td>8.669570e-01</td>\n",
       "      <td>4.235753e-01</td>\n",
       "      <td>1.044400e+00</td>\n",
       "      <td>4.465373e-15</td>\n",
       "      <td>3.155231e-01</td>\n",
       "      <td>3.668152e-01</td>\n",
       "      <td>1.991853e-15</td>\n",
       "      <td>-2.136316e-17</td>\n",
       "      <td>2.495579e-17</td>\n",
       "      <td>3.761558e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2.028757e+01</td>\n",
       "      <td>1.813092e+01</td>\n",
       "      <td>3.106073e+01</td>\n",
       "      <td>4.362695e+01</td>\n",
       "      <td>6.499011e+00</td>\n",
       "      <td>2.148716e+01</td>\n",
       "      <td>9.069650e+00</td>\n",
       "      <td>4.228960e+00</td>\n",
       "      <td>1.264320e+02</td>\n",
       "      <td>1.464080e+01</td>\n",
       "      <td>2.170529e+01</td>\n",
       "      <td>1.292162e+00</td>\n",
       "      <td>2.522409e+00</td>\n",
       "      <td>3.237988e+01</td>\n",
       "      <td>2.065742e+00</td>\n",
       "      <td>1.733947e+00</td>\n",
       "      <td>2.327725e+01</td>\n",
       "      <td>1.994105e+00</td>\n",
       "      <td>1.705625e+00</td>\n",
       "      <td>8.514747e+01</td>\n",
       "      <td>1.739366e+00</td>\n",
       "      <td>1.418329e+01</td>\n",
       "      <td>2.067495e+00</td>\n",
       "      <td>2.203615e+01</td>\n",
       "      <td>3.256142e+00</td>\n",
       "      <td>2.244331e+00</td>\n",
       "      <td>3.852470e+01</td>\n",
       "      <td>4.122493e+00</td>\n",
       "      <td>3.211858e+00</td>\n",
       "      <td>1.591958e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis      DER_pt_h  \\\n",
       "count  2.500000e+05                 2.500000e+05  2.500000e+05  2.500000e+05   \n",
       "mean  -1.060130e-17                 1.880096e-17  1.267608e-17 -1.631406e-17   \n",
       "std    1.000000e+00                 1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.138668e+00                -1.393124e+00 -1.833343e+00 -9.095176e-01   \n",
       "25%   -4.965607e-01                -8.487457e-01 -5.337725e-01 -6.885043e-01   \n",
       "50%   -3.602904e-02                -7.683769e-02 -1.819794e-01 -3.052117e-01   \n",
       "75%    1.658339e-01                 6.891572e-01  2.713048e-01  3.341892e-01   \n",
       "max    2.028757e+01                 1.813092e+01  3.106073e+01  4.362695e+01   \n",
       "\n",
       "       DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "count          2.500000e+05      2.500000e+05         2.500000e+05   \n",
       "mean          -8.583356e-18     -1.472245e-17         8.242296e-18   \n",
       "std            1.000000e+00      1.000000e+00         1.000000e+00   \n",
       "min           -2.561276e+00     -1.671947e+00        -8.931170e+00   \n",
       "25%            8.928376e-15     -5.058597e-15        -1.206744e-15   \n",
       "50%            8.928376e-15     -5.058597e-15        -1.206744e-15   \n",
       "75%            8.928376e-15     -5.058597e-15        -1.206744e-15   \n",
       "max            6.499011e+00      2.148716e+01         9.069650e+00   \n",
       "\n",
       "       DER_deltar_tau_lep    DER_pt_tot    DER_sum_pt  DER_pt_ratio_lep_tau  \\\n",
       "count        2.500000e+05  2.500000e+05  2.500000e+05          2.500000e+05   \n",
       "mean         2.302158e-17 -8.014922e-18 -2.677325e-17         -6.988898e-17   \n",
       "std          1.000000e+00  1.000000e+00  1.000000e+00          1.000000e+00   \n",
       "min         -2.765448e+00 -8.493204e-01 -9.708062e-01         -1.646192e+00   \n",
       "25%         -7.192385e-01 -7.217697e-01 -6.990315e-01         -6.565422e-01   \n",
       "50%          1.512306e-01 -2.963986e-01 -3.264107e-01         -1.865768e-01   \n",
       "75%          7.509156e-01  3.894166e-01  3.633864e-01          4.017679e-01   \n",
       "max          4.228960e+00  1.264320e+02  1.464080e+01          2.170529e+01   \n",
       "\n",
       "       DER_met_phi_centrality  DER_lep_eta_centrality    PRI_tau_pt  \\\n",
       "count            2.500000e+05            2.500000e+05  2.500000e+05   \n",
       "mean            -7.356959e-16           -5.556444e-17  4.973799e-17   \n",
       "std              1.000000e+00            1.000000e+00  1.000000e+00   \n",
       "min             -1.077171e+00           -2.133972e+00 -8.347025e-01   \n",
       "25%             -1.041145e+00            4.104437e-15 -6.298241e-01   \n",
       "50%             -1.907659e-01            4.104437e-15 -3.080222e-01   \n",
       "75%              1.133815e+00            4.104437e-15  2.815259e-01   \n",
       "max              1.292162e+00            2.522409e+00  3.237988e+01   \n",
       "\n",
       "        PRI_tau_eta   PRI_tau_phi    PRI_lep_pt   PRI_lep_eta   PRI_lep_phi  \\\n",
       "count  2.500000e+05  2.500000e+05  2.500000e+05  2.500000e+05  2.500000e+05   \n",
       "mean  -4.428102e-17  9.094947e-18 -2.725642e-17  6.201617e-17  2.148681e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.049313e+00 -1.724952e+00 -9.363372e-01 -1.964844e+00 -1.753563e+00   \n",
       "25%   -7.528565e-01 -8.624289e-01 -6.474171e-01 -7.861712e-01 -8.617931e-01   \n",
       "50%   -9.906238e-03 -1.366657e-02 -2.784604e-01 -2.015248e-02  2.337156e-02   \n",
       "75%    7.486937e-01  8.659198e-01  3.049996e-01  7.735346e-01  8.667000e-01   \n",
       "max    2.065742e+00  1.733947e+00  2.327725e+01  1.994105e+00  1.705625e+00   \n",
       "\n",
       "            PRI_met   PRI_met_phi  PRI_met_sumet   PRI_jet_num  \\\n",
       "count  2.500000e+05  2.500000e+05   2.500000e+05  2.500000e+05   \n",
       "mean   1.023182e-17 -3.541345e-17  -3.922196e-17  1.925912e-15   \n",
       "std    1.000000e+00  1.000000e+00   1.000000e+00  1.000000e+00   \n",
       "min   -1.264892e+00 -1.728199e+00  -1.550355e+00 -1.001790e+00   \n",
       "25%   -6.177055e-01 -8.635146e-01  -6.860080e-01 -1.001790e+00   \n",
       "50%   -2.102234e-01 -7.659549e-03  -2.376150e-01  2.130493e-02   \n",
       "75%    3.094045e-01  8.669570e-01   4.235753e-01  1.044400e+00   \n",
       "max    8.514747e+01  1.739366e+00   1.418329e+01  2.067495e+00   \n",
       "\n",
       "       PRI_jet_leading_pt  PRI_jet_leading_eta  PRI_jet_leading_phi  \\\n",
       "count        2.500000e+05         2.500000e+05         2.500000e+05   \n",
       "mean         7.162271e-18        -2.131628e-18         1.347189e-17   \n",
       "std          1.000000e+00         1.000000e+00         1.000000e+00   \n",
       "min         -1.166369e+00        -3.251405e+00        -2.227403e+00   \n",
       "25%         -5.825900e-01        -3.107866e-01        -3.868959e-01   \n",
       "50%          4.465373e-15        -3.438908e-19        -7.296359e-17   \n",
       "75%          4.465373e-15         3.155231e-01         3.668152e-01   \n",
       "max          2.203615e+01         3.256142e+00         2.244331e+00   \n",
       "\n",
       "       PRI_jet_subleading_pt  PRI_jet_subleading_eta  PRI_jet_subleading_phi  \\\n",
       "count           2.500000e+05            2.500000e+05            2.500000e+05   \n",
       "mean           -4.868639e-17            1.516298e-17           -2.434319e-17   \n",
       "std             1.000000e+00            1.000000e+00            1.000000e+00   \n",
       "min            -1.606480e+00           -4.100846e+00           -3.208624e+00   \n",
       "25%             1.991853e-15           -2.136316e-17            2.495579e-17   \n",
       "50%             1.991853e-15           -2.136316e-17            2.495579e-17   \n",
       "75%             1.991853e-15           -2.136316e-17            2.495579e-17   \n",
       "max             3.852470e+01            4.122493e+00            3.211858e+00   \n",
       "\n",
       "       PRI_jet_all_pt  \n",
       "count    2.500000e+05  \n",
       "mean    -5.082654e-16  \n",
       "std      1.000000e+00  \n",
       "min     -7.454379e-01  \n",
       "25%     -7.454379e-01  \n",
       "50%     -3.321111e-01  \n",
       "75%      3.761558e-01  \n",
       "max      1.591958e+01  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hb = (hb - hb.mean()) / hb.std()\n",
    "hb = hb.fillna(0)\n",
    "hb = (hb - hb.mean()) / hb.std()\n",
    "hb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX = np.c_[np.ones(X.shape[0]), hb.to_numpy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3404106662758695\n"
     ]
    }
   ],
   "source": [
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"\n",
    "    Linear regression using gradient descent.\n",
    "    Uses MSE.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y:  ndarray\n",
    "        the labels\n",
    "    tx: ndarray\n",
    "        vector x tilde, i.e. the parameters with a bias term\n",
    "    initial_w: ndarray\n",
    "        initial weight vector\n",
    "    max_iters: int\n",
    "        maximum number of iterations\n",
    "    gamma: float\n",
    "        learning rate\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (ndarray, float)\n",
    "        Last weight vector and the corresponding loss value\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_e(y, tx, w):\n",
    "        return y - tx @ w\n",
    "    \n",
    "    def compute_loss(n2, e):\n",
    "        return (e.T @ e) / n2\n",
    "    \n",
    "    def compute_gradient(tx, n, e):\n",
    "        return - tx.T @ e / n\n",
    "    \n",
    "    loss = 0\n",
    "    w = initial_w\n",
    "    n = y.shape[0]\n",
    "    n2 = n*2\n",
    "    \n",
    "    for n_iter in range(max_iters):\n",
    "        e = compute_e(y, tx, w)\n",
    "        gradient = compute_gradient(tx, n, e)\n",
    "        loss = compute_loss(n2, e)\n",
    "        \n",
    "        # Update weights\n",
    "        w -= gamma * gradient\n",
    "        #print(\"Gradient Descent({bi}/{ti}): loss={l}, w={w}\".format(\n",
    "        #      bi=n_iter, ti=max_iters - 1, l=loss, w=w[0]))\n",
    "\n",
    "    return w, loss\n",
    "'''\n",
    "weights = np.array([])\n",
    "for i in range(100):\n",
    "    initial_w = np.full(tX.shape[1], i/100)\n",
    "    max_iters = 100\n",
    "    gamma = 0.3\n",
    "    w, loss = least_squares_GD(y, tX, initial_w, max_iters, gamma)\n",
    "    weights = np.append(weights, loss)\n",
    "idx = np.argmin(weights)\n",
    "'''\n",
    "initial_w = np.zeros(tX.shape[1])\n",
    "max_iters = 1000\n",
    "gamma = 0.3\n",
    "w, loss = least_squares_GD(y, tX, initial_w, max_iters, gamma)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34672967168835184\n"
     ]
    }
   ],
   "source": [
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"\n",
    "    Linear regression using gradient descent.\n",
    "    Uses MAE.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y:  ndarray\n",
    "        the labels\n",
    "    tx: ndarray\n",
    "        vector x tilde, i.e. the parameters with a bias term\n",
    "    initial_w: ndarray\n",
    "        initial weight vector\n",
    "    max_iters: int\n",
    "        maximum number of iterations\n",
    "    gamma: float\n",
    "        learning rate\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (ndarray, float)\n",
    "        Last weight vector and the corresponding loss value\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_e(y, tx, w):\n",
    "        return y - tx @ w\n",
    "    \n",
    "    def compute_loss(n, e):\n",
    "        return 1/n * np.sum(np.abs(e))\n",
    "    \n",
    "    def compute_gradient(tx, n, e):\n",
    "        e = y - tx @ w\n",
    "    \n",
    "        return -1/n*tx.T @ np.sign(e)\n",
    "    \n",
    "    loss = 0\n",
    "    w = initial_w\n",
    "    n = y.shape[0]\n",
    "    n2 = n*2\n",
    "    \n",
    "    for n_iter in range(max_iters):\n",
    "        e = compute_e(y, tx, w)\n",
    "        gradient = compute_gradient(tx, n, e)\n",
    "        loss = compute_loss(n2, e)\n",
    "        \n",
    "        # Update weights\n",
    "        w -= gamma * gradient\n",
    "        #print(\"Gradient Descent({bi}/{ti}): loss={l}, w={w}\".format(\n",
    "        #      bi=n_iter, ti=max_iters - 1, l=loss, w=w[0]))\n",
    "\n",
    "    return w, loss\n",
    "\n",
    "initial_w = np.zeros(tX.shape[1])\n",
    "max_iters = 1000\n",
    "gamma = 0.3\n",
    "w, loss = least_squares_GD(y, tX, initial_w, max_iters, gamma)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4915113296368542\n"
     ]
    }
   ],
   "source": [
    "def least_squares_SGD(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"\n",
    "    Linear regression using stochastic gradient descent.\n",
    "    Uses MAE.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y:  ndarray\n",
    "        the labels\n",
    "    tx: ndarray\n",
    "        vector x tilde, i.e. the parameters with a bias term\n",
    "    initial_w: ndarray\n",
    "        initial weight vector\n",
    "    max_iters: int\n",
    "        maximum number of iterations\n",
    "    gamma: float\n",
    "        learning rate\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (ndarray, float)\n",
    "        Last weight vector and the corresponding loss value\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_e(y, tx, w):\n",
    "        return y - tx @ w\n",
    "    \n",
    "    def compute_loss(n2, e):\n",
    "        return (e.T @ e) / n2\n",
    "    \n",
    "    def compute_gradient(tx, n, e):\n",
    "        return - tx.T @ e / n\n",
    "    \n",
    "    loss = 0\n",
    "    w = initial_w[:, np.newaxis]\n",
    "    n = y.shape[0]\n",
    "    n2 = n*2\n",
    "    data_size = len(y)\n",
    "    shuffled_indices = np.random.permutation(np.arange(data_size))\n",
    "    shuffled_y = y[shuffled_indices]\n",
    "    shuffled_tx = tx[shuffled_indices]\n",
    "    shuffled_y = shuffled_y[:,np.newaxis]\n",
    "    for n_iter, by, btx in zip(range(max_iters), shuffled_y, shuffled_tx):\n",
    "        by = by[np.newaxis]\n",
    "        btx = btx[np.newaxis, :]\n",
    "        e = compute_e(by, btx, w)\n",
    "        gradient = compute_gradient(btx, n, e)\n",
    "        loss = compute_loss(n2, e)\n",
    "        \n",
    "        # Update weights\n",
    "        w -= gamma * gradient\n",
    "        #print(\"Gradient Descent({bi}/{ti}): loss={l}, w={w}\".format(\n",
    "        #      bi=n_iter, ti=max_iters - 1, l=loss, w=w[0]))\n",
    "    return w, compute_loss(n2, compute_e(y, tx, w[:,0]))\n",
    "\n",
    "initial_w = np.full(tX.shape[1], 0.1)\n",
    "max_iters = 100000\n",
    "gamma = 0.7\n",
    "w, loss = least_squares_SGD(y, tX, initial_w, max_iters, gamma)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34040945216155494\n"
     ]
    }
   ],
   "source": [
    "def least_squares(y, tx):\n",
    "    \"\"\"\n",
    "    Linear regression using normal equations.\n",
    "    Use MSE loss function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y:  ndarray\n",
    "        the labels\n",
    "    tx: ndarray\n",
    "        vector x tilde, i.e. the parameters with a bias term\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (ndarray, float)\n",
    "        Last weight vector and the corresponding loss value\n",
    "    \"\"\"    \n",
    "    def compute_e(y, tx, w):\n",
    "        return y - tx @ w\n",
    "    \n",
    "    def compute_loss(n2, e):\n",
    "        return (e.T @ e) / n2\n",
    "    \n",
    "    w = la.solve(tx.T @ tx, tx.T @ y)\n",
    "    \n",
    "    return w, compute_loss(y.shape[0]*2, compute_e(y, tx, w))\n",
    "\n",
    "w, loss = least_squares(y, tX)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    \"\"\"\n",
    "    Ridge regression using normal equations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : ndarray\n",
    "        Description of y\n",
    "    ...\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (ndarray, float)\n",
    "        Last weight vector and the corresponding loss value\n",
    "    \"\"\" \n",
    "    \n",
    "            \n",
    "    def compute_e(y, tx, w):\n",
    "        return y - tx @ w\n",
    "    \n",
    "    def compute_loss(n2, e):\n",
    "        return (e.T @ e) / n2\n",
    "    \n",
    "    \n",
    "    X = tx.T @ tx\n",
    "    w = la.solve(X + lambda_ * (2*y.shape[0]) * np.eye(X.shape[0]), tx.T @ y)\n",
    "    return w, compute_loss(y.shape[0]*2, compute_e(y, tx, w))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.000, Training RMSE=0.583\n",
      "lambda=0.000, Training RMSE=0.583\n",
      "lambda=0.000, Training RMSE=0.583\n",
      "lambda=0.000, Training RMSE=0.583\n",
      "lambda=0.000, Training RMSE=0.583\n",
      "lambda=0.001, Training RMSE=0.583\n",
      "lambda=0.001, Training RMSE=0.583\n",
      "lambda=0.003, Training RMSE=0.583\n",
      "lambda=0.007, Training RMSE=0.584\n",
      "lambda=0.016, Training RMSE=0.584\n",
      "lambda=0.037, Training RMSE=0.586\n",
      "lambda=0.085, Training RMSE=0.590\n",
      "lambda=0.193, Training RMSE=0.598\n",
      "lambda=0.439, Training RMSE=0.613\n",
      "lambda=1.000, Training RMSE=0.634\n",
      "0.3404162668067664\n"
     ]
    }
   ],
   "source": [
    "def ridge_regression_demo(tx, y):\n",
    "\n",
    "    \n",
    "    \"\"\"ridge regression demo.\"\"\"\n",
    "    # define parameter\n",
    "    lambdas = np.logspace(-5, 0, 15)\n",
    "    \n",
    "    rmse_tr = []\n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "        weights, loss = ridge_regression(y, tx, lambda_)\n",
    "        rmse_tr.append(np.sqrt(loss))\n",
    "\n",
    "        print(\"lambda={l:.3f}, Training RMSE={tr:.3f}\".format(l=lambda_, tr=rmse_tr[ind]))\n",
    "        \n",
    "\n",
    "ridge_regression_demo(tX, y)\n",
    "\n",
    "w, loss = ridge_regression(y, tX, 0.001)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    \"\"\"apply sigmoid function on t.\"\"\"\n",
    "    return 1/(1 + np.exp(-t))\n",
    "    \n",
    "def calculate_loss(y, tx, w):\n",
    "    \"\"\"compute the cost by negative log likelihood.\"\"\"\n",
    "    return np.sum(np.log(1 + np.exp(tx @ w)) - y * (tx @ w))\n",
    "\n",
    "\n",
    "def calculate_gradient(y, tx, w):\n",
    "    \"\"\"compute the gradient of loss.\"\"\"\n",
    "    return tx.T @ (sigmoid(tx@w) - y)\n",
    "\n",
    "\n",
    "def logistic_regression_step(y, tx, w):\n",
    "    \"\"\"return the loss, gradient\"\"\"\n",
    "    return calculate_loss(y, tx, w), calculate_gradient(y, tx, w)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def logistic_regression(y, tx, lambda_):\n",
    "    \"\"\"\n",
    "    Logistic regression using gradient descent or SGD.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : ndarray\n",
    "        Description of y\n",
    "    ...\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (ndarray, float)\n",
    "        Last weight vector and the corresponding loss value\n",
    "    \"\"\"  \n",
    "    def learning_by_gradient_descent(y, tx, w, gamma):\n",
    "        \"\"\"\n",
    "        Do one step of gradient descen using logistic regression.\n",
    "        Return the loss and the updated w.\n",
    "        \"\"\"\n",
    "        loss = calculate_loss(y, tx, w)\n",
    "        gradient = calculate_gradient(y,tx,w)\n",
    "        w = w - gamma * gradient\n",
    "        return loss, w\n",
    "    \n",
    "    # init parameters\n",
    "    max_iter = 10000\n",
    "    threshold = 1e-8\n",
    "    #gamma = 0.01\n",
    "    losses = []\n",
    "\n",
    "    # build tx\n",
    "    w = np.zeros((tx.shape[1], 1))\n",
    "    y = y[:,np.newaxis]\n",
    "\n",
    "    # start the logistic regression\n",
    "    for iter in range(max_iter):\n",
    "        # get loss and update w.\n",
    "        loss, w = learning_by_gradient_descent(y, tx, w, lambda_)\n",
    "        # log info\n",
    "        if iter % 100 == 0:\n",
    "            print(\"Current iteration={i}, loss={l}\".format(i=iter, l=loss))\n",
    "        # converge criterion\n",
    "        losses.append(loss)\n",
    "        if len(losses) > 1 and np.abs(losses[-1] - losses[-2]) < threshold:\n",
    "            break\n",
    "     \n",
    "    print(\"loss={l}\".format(l=calculate_loss(y, tx, w)))\n",
    "    return w, losses[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lambda_ = 1e-8\n",
    "w, loss = logistic_regression(y, tX, lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def reg_logistic_regression(y, tx, lambda_):\n",
    "    \"\"\"\n",
    "    Regularized logistic regression using gradient descent or SGD.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : ndarray\n",
    "        Description of y\n",
    "    ...\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (ndarray, float)\n",
    "        Last weight vector and the corresponding loss value\n",
    "    \"\"\"    \n",
    "    def penalized_logistic_regression(y, tx, w, lambda_):\n",
    "        \"\"\"return the loss, gradient\"\"\"\n",
    "        loss, gradient = logistic_regression_step(y, tx, w)\n",
    "        loss     += 2 * lambda_ * la.norm(w)**2\n",
    "        gradient += lambda_ * w\n",
    "\n",
    "        return loss, gradient\n",
    "    \n",
    "    def learning_by_penalized_gradient(y, tx, w, gamma, lambda_):\n",
    "        \"\"\"\n",
    "        Do one step of gradient descent, using the penalized logistic regression.\n",
    "        Return the loss and updated w.\n",
    "        \"\"\"\n",
    "        loss, gradient = penalized_logistic_regression(y, tx, w, lambda_) \n",
    "        w = w - gamma * gradient \n",
    "\n",
    "        return loss, w\n",
    "    \n",
    "    # init parameters\n",
    "    max_iter = 10000\n",
    "    gamma = 1e-8\n",
    "    threshold = 1e-8\n",
    "    losses = []\n",
    "\n",
    "    w = np.zeros((tx.shape[1], 1))\n",
    "    y = y[:,np.newaxis]\n",
    "\n",
    "    # start the logistic regression\n",
    "    for iter in range(max_iter):\n",
    "        # get loss and update w.\n",
    "        loss, w = learning_by_penalized_gradient(y, tx, w, gamma, lambda_)\n",
    "        # log info\n",
    "        if iter % 100 == 0:\n",
    "            print(\"Current iteration={i}, loss={l}\".format(i=iter, l=loss))\n",
    "        # converge criterion\n",
    "        losses.append(loss)\n",
    "        if len(losses) > 1 and np.abs(losses[-1] - losses[-2]) < threshold:\n",
    "            break\n",
    "            \n",
    "    print(\"loss={l}\".format(l=calculate_loss(y, tx, w)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lambda_ = 0.000001\n",
    "w, loss = reg_logistic_regression(y, tX, lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "hbt = pd.read_csv(DATA_TEST_PATH, sep=',')\n",
    "hbt = hbt.drop(['Id', 'Prediction'], 1)\n",
    "hbt = hbt.replace(-999, np.nan)\n",
    "hbt = (hbt - hbt.mean()) / hbt.std()\n",
    "hbt = hbt.fillna(0)\n",
    "hbt = (hbt - hbt.mean()) / hbt.std()\n",
    "tX_test = hbt.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'predictions.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w[1:], tX_test)#[:, [0, 1, 2, 3, 4, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]]) # Selected desired columns\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_pred))\n",
    "print(len(y_pred[y_pred > 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submissions scores\n",
    "Best score by technique\n",
    "\n",
    "<ul>\n",
    "    <li>MSE, gradient descent : 0.649</li>\n",
    "    <li>MAE, gradient descent : 0.678 </li>\n",
    "    <li>ridge regression      : 0.664</li>\n",
    "</ul>\n",
    "Best score after not being stupid with bias:\n",
    "\n",
    "* MSE, GD: \n",
    "* MAE, GD: 0.639\n",
    "* LSQ: 0.706\n",
    "* R-REG: 0.730\n",
    "\n",
    "Best score after normalizing test set + putting zero where unknown:\n",
    "\n",
    "* LSQ: 0.723\n",
    "* R-REG: 0.719\n",
    "\n",
    "Feature expansion?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
