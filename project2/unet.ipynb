{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thGdzJB464GA"
   },
   "source": [
    "# U-Net for Road Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TTDeMTliVR1w"
   },
   "source": [
    "## Required Folder Structure\n",
    "\n",
    "The working folder contains the following subfolders:\n",
    "* `training` Contains:\n",
    "    * `groundtruth` Contains the groudtruth images (format: `satImage_xxx.png`)\n",
    "    * `images` Contains the images to segment (format: `satImage_xxx.png`)\n",
    "* `predictions_submission` Will contain the images predicted to create a submission\n",
    "* `test_set_images` Contains the test images used to create a submission (format: `test_x.png` or `test_xx.png`)\n",
    "\n",
    "This folder also contains 2 files:\n",
    "* `road_segmentation_model.h5` Saved version the model. Allows to save the weights of the previous training that was done\n",
    "* `smooth_tiled_prediction.py` Present in the GitHub repo.\n",
    "\n",
    "In another folder we will store the autogenerated images. This folder should be called `augmented_set`.\n",
    "In this folder there must be 2 subfolders:\n",
    "* `groundtruth` contains autogenerated groundtruths\n",
    "* `images` contains autogenerates images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from itertools import chain\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from PIL import Image\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import sklearn.metrics\n",
    "from smooth_tiled_predictions import predict_img_with_smooth_windowing\n",
    "from time import strftime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant Definitions\n",
    "\n",
    "#### Non-Tweakable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_L7q7mx764GG"
   },
   "outputs": [],
   "source": [
    "# Image definition\n",
    "IMG_WIDTH    = 400\n",
    "IMG_HEIGHT   = 400\n",
    "IMG_CHANNELS = 3\n",
    "PIXEL_DEPTH  = 255\n",
    "\n",
    "# Folder definitions\n",
    "IMAGE_DATA_PATH           = 'training/images/'\n",
    "MASK_DATA_PATH            = 'training/groundtruth/'\n",
    "MODEL_SAVE_LOCATION       = 'road_segmentation_model.h5'\n",
    "SUBMISSION_DATA_DIR       = 'test_set_images/'\n",
    "PREDICTION_SUBMISSION_DIR = 'predictions_submission/'\n",
    "\n",
    "IMAGES_FILENAMES = os.listdir(IMAGE_DATA_PATH)\n",
    "\n",
    "# Image generation\n",
    "OUTPUT_DATA_IMAGE_PATH = 'augmented_set/'\n",
    "\n",
    "# Seeding\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed = SEED\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Checkpoints\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir  = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweakable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image generation\n",
    "GENERATE_NEW_IMG   = False\n",
    "USE_GENERATED_IMG  = True\n",
    "IMG_TO_GEN_PER_IMG = 100\n",
    "\n",
    "# Load existing model\n",
    "USE_SAVED_MODEL = True\n",
    "\n",
    "# F1-score estimation\n",
    "NUMBER_OF_IMG_TO_TEST = 10\n",
    "\n",
    "# Predictions\n",
    "RUN_PREDICTIONS_ON_TEST_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Z0Y6QXYZEcnG",
    "outputId": "5d2710ca-3c24-40c3-a56d-5040c02a9733"
   },
   "outputs": [],
   "source": [
    "if GENERATE_NEW_IMG:\n",
    "    # load the input image, convert it to a NumPy array, and then\n",
    "    # reshape it to have an extra dimension\n",
    "    for img in tqdm(IMAGES_FILENAMES):\n",
    "        image = load_img(IMAGE_DATA_PATH+img)\n",
    "        image = img_to_array(image)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "\n",
    "        truth = load_img(MASK_DATA_PATH+img)\n",
    "        truth = img_to_array(truth)\n",
    "        truth = np.expand_dims(truth, axis=0)\n",
    "        # construct the image generator for data augmentation then\n",
    "        # initialize the total number of images generated thus far\n",
    "        aug = ImageDataGenerator(rotation_range=360,\n",
    "                  zoom_range=0.3,\n",
    "                  brightness_range=[0.7,1],\n",
    "                  width_shift_range=0.1,\n",
    "                  height_shift_range=0.1,\n",
    "                  vertical_flip=True,\n",
    "                  shear_range=0.15,\n",
    "                  horizontal_flip=True,\n",
    "                  fill_mode=\"reflect\")\n",
    "        total = 0\n",
    "\n",
    "        # construct the actual Python generator\n",
    "        imageGen = aug.flow(image, y=truth, batch_size=1, save_to_dir=OUTPUT_DATA_IMAGE_PATH + \"images\",\n",
    "          save_prefix=img.split(\".\")[0], save_format=\"png\", seed = SEED )\n",
    "        truthGen = aug.flow(truth, y=truth, batch_size=1, save_to_dir=OUTPUT_DATA_IMAGE_PATH + \"groundtruth\",\n",
    "          save_prefix=img.split(\".\")[0], save_format=\"png\", seed = SEED )\n",
    "        # loop over examples from our image data augmentation generator\n",
    "        for image in imageGen:\n",
    "            # increment our counter\n",
    "            total += 1\n",
    "\n",
    "            # if we have reached the specified number of examples, break\n",
    "            # from the loop\n",
    "            if total == IMG_TO_GEN_PER_IMG:\n",
    "                break\n",
    "\n",
    "        total = 0\n",
    "        for image in truthGen:\n",
    "            # increment our counter\n",
    "            total += 1\n",
    "\n",
    "            # if we have reached the specified number of examples, break\n",
    "            # from the loop\n",
    "            if total == IMG_TO_GEN_PER_IMG:\n",
    "                break\n",
    "\n",
    "if(USE_GENERATED_IMG):\n",
    "    print(\"[INFO]: Updating images_filename\")\n",
    "    IMAGE_DATA_PATH = OUTPUT_DATA_IMAGE_PATH+'images/'\n",
    "    MASK_DATA_PATH = OUTPUT_DATA_IMAGE_PATH+ 'groundtruth/'\n",
    "    print(\"[INFO]: new MASK_DATA_PATH : \"+ MASK_DATA_PATH)\n",
    "    print(\"[INFO]: new IMAGE_DATA_PATH : \" + IMAGE_DATA_PATH)\n",
    "    IMAGES_FILENAMES = os.listdir(IMAGE_DATA_PATH)\n",
    "    print(\"[INFO]: There are \" + str(len(IMAGES_FILENAMES)) + \" found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "CdChAiSz64GM",
    "outputId": "50aafe6f-e1aa-476e-b2e2-db14778d240d"
   },
   "outputs": [],
   "source": [
    "np.random.seed = SEED\n",
    "print(\"[INFO]: Loading images into RAM\", flush = True)\n",
    "X = np.zeros((len(IMAGES_FILENAMES), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y = np.zeros((len(IMAGES_FILENAMES), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "\n",
    "for n, filename in tqdm(enumerate(IMAGES_FILENAMES), total=len(IMAGES_FILENAMES)):   \n",
    "    img = imread(IMAGE_DATA_PATH + filename)[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X[n] = img\n",
    "    mask = imread(MASK_DATA_PATH + filename)\n",
    "    mask = np.expand_dims(resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant',\n",
    "                                      preserve_range=True), axis=-1)\n",
    "    if USE_GENERATED_IMG:\n",
    "        Y[n] = mask[:,:,0]\n",
    "    else:\n",
    "        Y[n] = mask\n",
    "\n",
    "x_train=X \n",
    "y_train=Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dNVs_ebC64GW",
    "outputId": "be9e6407-4ac8-4e0d-da9f-68e0adcdf43f"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH,+ IMG_CHANNELS))\n",
    "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
    " \n",
    "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(s)\n",
    "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c1)\n",
    "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    " \n",
    "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(p1)\n",
    "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    " \n",
    "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(p2)\n",
    "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    " \n",
    "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(p3)\n",
    "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    " \n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(p4)\n",
    "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c5)\n",
    " \n",
    "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(u6)\n",
    "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c6)\n",
    " \n",
    "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(u7)\n",
    "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c7)\n",
    " \n",
    "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c8)\n",
    " \n",
    "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(u9)\n",
    "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c9)\n",
    " \n",
    "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    " \n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saved Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3iwGjW4564Ga",
    "outputId": "9281fd25-2808-4fb0-ba8e-ed19b5c94b97"
   },
   "outputs": [],
   "source": [
    "if USE_SAVED_MODEL:\n",
    "    if not os.path.isfile(MODEL_SAVE_LOCATION):\n",
    "        print(\"[ERROR]: Could not locate file for model weights. Proceding without loading weights.\")\n",
    "    else:\n",
    "        model.load_weights(MODEL_SAVE_LOCATION)\n",
    "        print(\"[INFO]: Loading saved model weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoints for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4_KzX5580rc"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "#!rm -rf ./logs/ \n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "callbacks = [\n",
    "  #tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "  tensorboard_callback,\n",
    "  cp_callback \n",
    "]\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "id": "04EK1s3B86yu",
    "outputId": "7b0f16f6-cc8e-416e-8ff7-b51907f9b845"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(10):\n",
    "    model.save_weights(f'road_segmentation_model_{i}.h5', overwrite=True)\n",
    "    results = model.fit(X, Y, validation_split=0.1, batch_size=32, epochs=100, callbacks=callbacks, shuffle=True)\n",
    "\n",
    "model.save_weights(MODEL_SAVE_LOCATION, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-Score Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opEJkx7OWpl3"
   },
   "outputs": [],
   "source": [
    " #https://github.com/kiteco/kite-python-blog-post-code/blob/master/image-segmentation/image_segmentation.py\n",
    "\n",
    "\"\"\"\n",
    "Helper functions used to estimate F1 score.\n",
    "\"\"\"\n",
    "\n",
    "def get_f1_score(groundtruth_list, predicted_list):\n",
    "    \"\"\"Return f1 score covering edge cases\"\"\"\n",
    "\n",
    "    tn, fp, fn, tp = get_confusion_matrix_elements(groundtruth_list, predicted_list)\n",
    "    \n",
    "    if _all_class_0_predicted_as_class_0(groundtruth_list, predicted_list) is True:\n",
    "        f1_score = 1\n",
    "    elif _all_class_1_predicted_as_class_1(groundtruth_list, predicted_list) is True:\n",
    "        f1_score = 1\n",
    "    else:\n",
    "        f1_score = (2 * tp) / ((2 * tp) + fp + fn)\n",
    "\n",
    "    return f1_score\n",
    "\n",
    "def get_confusion_matrix_elements(groundtruth_list, predicted_list):\n",
    "    \"\"\"returns confusion matrix elements i.e TN, FP, FN, TP as floats\n",
    "\tSee example code for helper function definitions\n",
    "    \"\"\"\n",
    "    _assert_valid_lists(groundtruth_list, predicted_list)\n",
    "\n",
    "    if _all_class_1_predicted_as_class_1(groundtruth_list, predicted_list) is True:\n",
    "        tn, fp, fn, tp = 0, 0, 0, np.float64(len(groundtruth_list))\n",
    "\n",
    "    elif _all_class_0_predicted_as_class_0(groundtruth_list, predicted_list) is True:\n",
    "        tn, fp, fn, tp = np.float64(len(groundtruth_list)), 0, 0, 0\n",
    "\n",
    "    else:\n",
    "        tn, fp, fn, tp = sklearn.metrics.confusion_matrix(groundtruth_list, predicted_list).ravel()\n",
    "        tn, fp, fn, tp = np.float64(tn), np.float64(fp), np.float64(fn), np.float64(tp)\n",
    "\n",
    "    return tn, fp, fn, tp\n",
    "\n",
    "def _assert_valid_lists(groundtruth_list, predicted_list):\n",
    "    assert len(groundtruth_list) == len(predicted_list)\n",
    "    for unique_element in np.unique(groundtruth_list).tolist():\n",
    "        assert unique_element in [0, 1]\n",
    "\n",
    "def _all_class_1_predicted_as_class_1(groundtruth_list, predicted_list):\n",
    "    _assert_valid_lists(groundtruth_list, predicted_list)\n",
    "    return np.unique(groundtruth_list).tolist() == np.unique(predicted_list).tolist() == [1]\n",
    "\n",
    "\n",
    "def _all_class_0_predicted_as_class_0(groundtruth_list, predicted_list):\n",
    "    _assert_valid_lists(groundtruth_list, predicted_list)\n",
    "    return np.unique(groundtruth_list).tolist() == np.unique(predicted_list).tolist() == [0]\n",
    "\n",
    "print(\"[INFO]: Estimating F1 score\", flush=True)\n",
    "step = 0.001\n",
    "start = 0.51\n",
    "stop = 0.53\n",
    "F1s = []\n",
    "thresholds = np.arange(start,stop+step,step)\n",
    "for threshold in thresholds:\n",
    "    F1_accumulator = 0\n",
    "\n",
    "    for idx in tqdm(range(NUMBER_OF_IMG_TO_TEST)):\n",
    "        x=np.array(x_train[idx])\n",
    "        x=np.expand_dims(x, axis=0)\n",
    "        predict = model.predict(x, verbose=0)\n",
    "\n",
    "        predict = (predict > threshold).astype(np.uint8)\n",
    "        f1 = get_f1_score(y_train[idx].flatten(),predict[0].flatten())\n",
    "        F1_accumulator += f1\n",
    "    #print(\"\\nAverage F1: \" + str(F1_accumulator / NUMBER_OF_IMG_TO_TEST))\n",
    "    F1s.append(F1_accumulator / NUMBER_OF_IMG_TO_TEST)\n",
    "best_index = np.argmax(F1s)\n",
    "best_threshold = thresholds[best_index]\n",
    "best_F1 = F1s[best_index]\n",
    "print(f\"\\nThe best threshold is {best_threshold}, yielding an average F1 score of {best_F1*100:.2f}\")\n",
    "plt.plot(thresholds, F1s);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Demo on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z1aJ3hP_64Gn"
   },
   "outputs": [],
   "source": [
    "def get_prediction(img):\n",
    "    x=np.array(img)\n",
    "    x=np.expand_dims(x, axis=0)\n",
    "    predict = model.predict(x, verbose=1)\n",
    "    print(predict.shape)\n",
    "    predict = (predict > best_threshold).astype(np.uint8)\n",
    "    predict = np.squeeze(predict[0])\n",
    "    print(predict.shape)\n",
    "\n",
    "    return predict\n",
    "\n",
    "idx = 4\n",
    "prediction = get_prediction(x_train[idx])\n",
    "\n",
    "print(\"- Original Image:\")\n",
    "imshow(x_train[idx])\n",
    "plt.show()\n",
    "\n",
    "print(\"- Prediction:\")\n",
    "imshow(prediction)\n",
    "plt.show()\n",
    "\n",
    "print(\"- Original Groundtruth:\")\n",
    "imshow(np.squeeze(y_train[idx]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dc-7HbbA64G1"
   },
   "source": [
    "### Running Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gINwpt1e64G5",
    "outputId": "41b7b119-5c85-4c1c-ae1b-869c9fcd5148"
   },
   "outputs": [],
   "source": [
    "def img_float_to_uint8(img):\n",
    "    rimg = img - np.min(img)\n",
    "    rimg = (rimg / np.max(rimg) * PIXEL_DEPTH).round().astype(np.uint8)\n",
    "    return rimg\n",
    "\n",
    "predictions = []\n",
    "if RUN_PREDICTIONS_ON_TEST_IMAGES:\n",
    "    print(\"[INFO]: Running prediction on submission set\")\n",
    "    if not os.path.isdir(PREDICTION_SUBMISSION_DIR):\n",
    "        os.mkdir(PREDICTION_SUBMISSION_DIR)\n",
    "    for i in range(1, 51):\n",
    "        pimg = imread(SUBMISSION_DATA_DIR + f\"test_{i}.png\")[:,:,:IMG_CHANNELS]\n",
    "        predictions.append(predict_img_with_smooth_windowing(\n",
    "            pimg,\n",
    "            window_size=IMG_WIDTH,\n",
    "            subdivisions=2,  # Minimal amount of overlap for windowing. Must be an even number.\n",
    "            nb_classes=1,\n",
    "                pred_func=(\n",
    "                    lambda img_batch_subdiv: model.predict(img_batch_subdiv)\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "else:\n",
    "    print(\"[INFO]: Skipping predicting test images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Zo8NOt41-WTy",
    "outputId": "beb3bd79-d8d3-4684-97f1-30c1272545b8"
   },
   "outputs": [],
   "source": [
    "if RUN_PREDICTIONS_ON_TEST_IMAGES:\n",
    "    print(\"[INFO]: Writing prediction to drive\")\n",
    "\n",
    "    ROAD_THRESHOLD = 0.25#0.1\n",
    "\n",
    "    pred = np.array(predictions.copy())\n",
    "    for i in range(1, 51):\n",
    "        pimg = pred[i-1]\n",
    "        w = pimg.shape[0]\n",
    "        h = pimg.shape[1]\n",
    "        cimg = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "        pimg = (pimg > best_threshold).astype(np.uint8)\n",
    "        pimg8 = np.squeeze(img_float_to_uint8(pimg))\n",
    "        cimg[:, :, 0] = pimg8\n",
    "        cimg[:, :, 1] = pimg8\n",
    "        cimg[:, :, 2] = pimg8\n",
    "        Image.fromarray(cimg).save(PREDICTION_SUBMISSION_DIR + f\"gt_{i}.png\")\n",
    "else:\n",
    "    print(\"[INFO]: Skipping write of predictions to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AICrowd Submission Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 926
    },
    "colab_type": "code",
    "id": "8zLUvSdc4Gab",
    "outputId": "040c75ea-3549-4331-d97c-6aa4fc965f1c"
   },
   "outputs": [],
   "source": [
    "# Creating ouput for submission\n",
    "\n",
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "# assign a label to a patch\n",
    "def patch_to_label(patch):\n",
    "    df = np.mean(patch)\n",
    "    if df > foreground_threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def mask_to_submission_strings(image_filename):\n",
    "    \"\"\"Reads a single image and outputs the strings that should go into the submission file\"\"\"\n",
    "    img_number = int(re.search(r\"\\d+\", image_filename).group(0))\n",
    "    im = mpimg.imread(image_filename)\n",
    "    patch_size = 16\n",
    "    for j in range(0, im.shape[1], patch_size):\n",
    "        for i in range(0, im.shape[0], patch_size):\n",
    "            patch = im[i:i + patch_size, j:j + patch_size]\n",
    "            label = patch_to_label(patch)\n",
    "            yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))\n",
    "\n",
    "\n",
    "def masks_to_submission(submission_filename, *image_filenames):\n",
    "    \"\"\"Converts images into a submission file\"\"\"\n",
    "    with open(submission_filename, 'w') as f:\n",
    "        f.write('id,prediction\\n')\n",
    "        for fn in image_filenames[0:]:\n",
    "            f.writelines('{}\\n'.format(s) for s in mask_to_submission_strings(fn))\n",
    "\n",
    "\n",
    "time = strftime(\"%Y%m%dT%H%M%S\")\n",
    "submission_filename = f'submission-{time}.csv'\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = f'{PREDICTION_SUBMISSION_DIR}gt_{i}.png'\n",
    "    image_filenames.append(image_filename)\n",
    "masks_to_submission(submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tweaking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 23\n",
    "input_img = imread(SUBMISSION_DATA_DIR + f\"test_{i}.png\")[:,:,:IMG_CHANNELS]\n",
    "\n",
    "predictions_smooth = predict_img_with_smooth_windowing(\n",
    "    input_img,\n",
    "    window_size=IMG_WIDTH,\n",
    "    subdivisions=2,  # Minimal amount of overlap for windowing. Must be an even number.\n",
    "    nb_classes=1,\n",
    "    pred_func=(\n",
    "        lambda img_batch_subdiv: model.predict(img_batch_subdiv)\n",
    "    )\n",
    ")\n",
    "\n",
    "predict = (predictions_smooth > 0.25).astype(np.uint8)\n",
    "\n",
    "imshow(np.squeeze(predict))\n",
    "plt.show()\n",
    "imshow(input_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://androidkt.com/tensorflow-keras-unet-for-image-image-segmentation/\n",
    "\n",
    "- https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277\n",
    "\n",
    "- https://arxiv.org/pdf/1505.04597.pdf"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "unet_try_jeremy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
