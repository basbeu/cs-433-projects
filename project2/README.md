# Road Segmentation Project
#### Bastien Beuchat, Robin Mamie, Jeremy Mion

Image segmentation is a computer vision process in which images are partitioned into different segments. It has a key role to play in many different fields of research. Among its concrete applications are domains such as medical imaging, machine vision and in our case dynamic map creation. Acquiring aerial photography is a cheap and efficient way of collecting information about the topography of the terrain below. In this project, we set out to create a machine learning algorithm that detects the roads out of these photographs. Automatically detecting the location and width of roads is a very powerful tool that allows map-making companies to keep their data up to date with very little cost.

In this project, we explore the different possibilities by starting with a simple convolutional neural network, and ending up with one implementing UNet++ using deep supervision.

## Requirements

The `run.py` script was developped using `Python 3.7.5`. The file `requirements.txt` contains all required libraries to run our project. To install all requirements, use the following command, using pip:

    pip install -r requirements.txt

Here is an explanatory list for our requirements (and their version number):

- tensorflow (2.0.0): model creation and training
- Keras (2.2.4): model creation and training
- numpy (1.17.4): general purpose library
- matplotlib (3.1.1): helper for the AIcrowd submission
- tqdm (4.40.2): shows user friendly progress bars in the console
- scikit_image (0.15.0): image handling
- Pillow (6.2.1): image handling

Download the `test_set_images.zip` and `training.zip` files directly from the *EPFL ML Road Segmentation 2019* AIcrowd challenge and put them into this folder. Please follow the instructions in the *Preparation* section.

### Performance

GPU usage is highly recommended. Even without training, the execution of `run.py` takes quite a bit of time. This project was done using `tensorflow-gpu==2.0.0` instead of the normal `tensorflow==2.0.0` package. A certain amount of RAM [is also needed](https://downloadmoreram.com/).

### Other external libraries

We also make use of the local file `smooth_tiled_predictions.py`. It was fetched from [this repository](https://github.com/Vooban/Smoothly-Blend-Image-Patches) (commit 2f5866bce03ac5edfecd1bacfdd8a0663c659f09), created by Guillaume Chevalier.
This file is very useful to apply our neural network on test images that are bigger than our training images.

### Preparation

The script works on test set images after the following manipulation on the original zip file. After unzipping the file directly at the root of this project (where this `README.md` is located), put all the images at the root of the created `test_set_images` folder:

    unzip test_set_images.zip
    mkdir test_set_images/tmp
    mv test_set_images/test_*/* test_set_images/tmp
    rm -r test_set_images/test_*
    mv test_set_images/tmp/* test_set_images
    rm -r test_set_images/tmp

This ensure that all test set images are at the root of the test_set_images folder.

To prepare the train set images:

    unzip training.zip

## Folder structure

The folders whose comments begin with a "*" are automatically generated by the script:

    .
    ├── augmented_set                # * Created with the provided script
    │   ├── groundtruth
    │   │   └── ...
    │   └── images
    │       └── ...
    ├── checkpoints                  # * Created to save training checkpoints
    ├── notebooks                    # Contains different notebooks used for development
    ├── predictions_submission       # * Folder where the predictions are saved
    ├── smooth_tiled_predictions.py  # External library, predict using bigger images than training set
    ├── test_set_images              # Folder created by unzipping test_set_images.zip and putting all the images at its root
    │   ├── test_1.png
    │   ├── ...
    │   └── test_50.png
    ├── training                     # Folder created by unzipping training.zip
    │   ├── groundtruth
    │   │   └── ...
    │   └── images
    │       └── ...
    ├── README.md                    # You are here
    ├── requirements.txt             # Python requirements
    ├── road_segmentation_model.h5   # Our best model
    ├── run.py                       # The main script
    └── validation_set               # * Created for dynamic thresholding
        ├── groundtruth
        │   └── ...
        └── images
            └── ...

## Create the best submission

To load our best model and create its submission, simply run the following:

    python run.py

This does not do any training. It loads the weights yielded after training a network based on UNet++ for 100 epochs on 10'000 images. The script then creates a file named `sumbission-<Ymd>T<HMS>.csv` (timestamped), ready to be uploaded on AIcrowd.

To create our best submission from scratch (with training), please use the following:

    python run.py -generate 100 --use-augmented-set --no-load -train 100 --search-threshold

Please note that any training will override the previous model. This means that our best model will be overridden at then end of the first training performed using this script.

### Note on GPU usage

The usage of a GPU does not necessarily create the same results, even with seeding, because of the use of non deterministic functions in `tensorflow-gpu==2.0.0`. We used GPUs throughout our entire project to speed up the execution.

## Flags

The help message of the script shows this:

    usage: run.py [-h] [-generate [number]] [--use-augmented-set]
                [-model [number]] [--no-load] [-train [epochs]]
                [--search-threshold] [-min-threshold [limit]]
                [-max-threshold [limit]] [-step-threshold [step]] [--no-predict]
                [--no-aicrowd] [--rtx]

    Prediction runner for the EPFL ML Road Segmentation 2019 Challenge. The
    default behaviour loads our best model and creates its AICrowd submission.

    optional arguments:
    -h, --help            show this help message and exit
    -generate [number]    Number of images to generate per train set image
                            (default 0)
    --use-augmented-set   Use the generated augmented train set (default False)
    -model [number]       Number of the model to use (default 1)
    --no-load             Do not load any previously saved model (default True)
    -train [epochs]       Number of epochs to train the neural network with
                            (default 0)
    --search-threshold    Search the best threshold on a validation set (default
                            False)
    -min-threshold [limit]
                            Minimum threshold search (default 0.39)
    -max-threshold [limit]
                            Maximum threshold search (default 0.41)
    -step-threshold [step]
                            Step for the threshold search (default 1e-3)
    --no-predict          Do not predict any image from the test set (default
                            True)
    --no-aicrowd          Do not generate file for AICrowd submission (default
                            True)
    --rtx                 Allow memory growth for RTX GPUs (default False)


### Model number

Here are the available models in the script run.py:

- 0: U-Net
- 1: U-Net++
- 2: U-Net++ with deep supervision
- 3: U-Net++ with deep supervision and a custom loss
